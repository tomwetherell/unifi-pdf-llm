{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dotenv\n",
    "\n",
    "# Load OpenAI API key from .env file\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "PDF_PATH = \"../data/train/SASOL Sustainability Report 2023 20-09_0.pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of pages: 109\n"
     ]
    }
   ],
   "source": [
    "# Load\n",
    "\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(PDF_PATH)\n",
    "pages = loader.load_and_split()\n",
    "\n",
    "print(f'Number of pages: {len(pages)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of splits: 778\n"
     ]
    }
   ],
   "source": [
    "# Split\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500, chunk_overlap=100, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(pages)\n",
    "\n",
    "print(f'Number of splits: {len(all_splits)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval and Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve\n",
    "\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'– Employee  – \\n– Service provider  – \\nLost Workday Case Rate (LWDCR)  0,13  0,10  0,14  0,11 Limited\\n– Employee  0,18  0,12  0,16  0,14 \\n– Service provider  0,10  0,08  0,11  0,08 \\nENERGY\\nLost Work Day Case Rate (LWDCR)  0,13  0,10 \\n– Employee  0,19  0,12 \\n– Service provider  0,09  0,08 \\nCHEMICALS\\nLost Work Day Case Rate (LWDCR)  0,13  0,15 \\n– Employee  0,10  0,19 \\n– Service provider  0,18  0,08 \\nCORPORATE CENTRE\\nLost Work Day Case Rate (LWDCR)  – \\n– Employee  – \\n– Service provider  – \\nEmployee and service provider fatalities  2  5  2  6 Limited\\n– Employee  1  4  1  3\\n– Service provider  1  1  1  3 \\nENERGY\\nEmployee and service provider fatalities  2  4\\n– Employee  1  4 \\n– Service provider  1  – \\nCHEMICALS\\nEmployee and service provider fatalities  –  1 \\n– Employee  –  – \\n– Service provider  –  1 \\nCORPORATE CENTRE\\nEmployee and service provider fatalities  –  – \\n– Employee  –  – \\n– Service provider  –  – \\nEmployee and service provider fatal injury frequency\\xa0rate  0,001  0,007'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs = retriever.invoke(\"What is Number of work-related fatalities\")\n",
    "retrieved_docs[4].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CORPORATE CENTRE\\nLost Work Day Case Rate (LWDCR)  – \\n– Employee  – \\n– Service provider  – \\nEmployee and service provider fatalities  2  5  2  6 Limited\\n– Employee  1  4  1  3\\n– Service provider  1  1  1  3 \\nENERGY\\nEmployee and service provider fatalities  2  4\\n– Employee  1  4 \\n– Service provider  1  – \\nCHEMICALS\\nEmployee and service provider fatalities  –  1 \\n– Employee  –  – \\n– Service provider  –  1 \\nCORPORATE CENTRE\\nEmployee and service provider fatalities  –  – \\n– Employee  –  –'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "TEMPLATE = \"\"\"Use the following pieces of context to answer the question at the end.\n",
    "If you don't know the answer, just say 'None', don't try to make up an answer.\n",
    "Only return the relevant number, without any additional text.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "custom_rag_prompt = PromptTemplate.from_template(TEMPLATE)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | custom_rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "answer = rag_chain.invoke(\"What was the B-BBEE (RSA only) - Black-owned spend. Please also provide the unit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'41 700 (Rands million)'"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1725.0\n"
     ]
    }
   ],
   "source": [
    "if answer == \"None\":\n",
    "    result = 0.0\n",
    "else:\n",
    "    result = answer.replace(\" \", \"\")\n",
    "\n",
    "print(float(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
