{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Table QA - RAG approach with tables converted to markdown format.\n",
    "\n",
    "See https://haystack.deepset.ai/tutorials/22_pipeline_with_promptnode\n",
    "\"\"\"\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "from haystack import Document\n",
    "from haystack.nodes import AzureConverter, EmbeddingRetriever, PromptNode, PromptTemplate, AnswerParser\n",
    "from haystack.document_stores import InMemoryDocumentStore\n",
    "from haystack.pipelines import Pipeline\n",
    "from haystack.utils import print_answers\n",
    "from haystack.nodes import BaseComponent\n",
    "from loguru import logger\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "AZURE_CONVERTER_KEY = os.environ.get(\"AZURE_CONVERTER_KEY\")\n",
    "\n",
    "AMKEY_TO_METRIC_PATH = \"/home/tomw/unifi-pdf-llm/data/AMKEY_GoldenStandard.csv\"\n",
    "AMKEY_TO_SYNONYM_PATH = \"/home/tomw/unifi-pdf-llm/data/ActivityMetricsSynonyms.csv\"\n",
    "AMKEY_TO_UNIT_PATH = \"/home/tomw/unifi-pdf-llm/data/AMKEY_unit_conversion.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_validation_pdf() -> list[Document]:\n",
    "    \"\"\"\n",
    "    Returns a list of Documents from the validation PDF.\n",
    "\n",
    "    Uses the AzureConverter to convert the PDF to tables and text documents.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    converted_docs : list[Document]\n",
    "        The list of Documents from the validation PDF.\n",
    "    \"\"\"\n",
    "    converted_docs = []\n",
    "    file_path = Path(\"/home/tomw/unifi-pdf-llm/data/validate/SASOL Sustainability Report 2023 20-09_0_minimal_split\")\n",
    "\n",
    "    converter = AzureConverter(\n",
    "        endpoint=\"https://azureconverter.cognitiveservices.azure.com/\",\n",
    "        credential_key=AZURE_CONVERTER_KEY,\n",
    "        model_id=\"prebuilt-layout\",  # Was \"prebuilt-document\"\n",
    "        save_json=True\n",
    "    )\n",
    "\n",
    "    for fn in file_path.glob(\"*.pdf\"):\n",
    "        print(f\"Converting {fn}\")\n",
    "        docs = converter.convert(file_path=fn, meta=None)\n",
    "        converted_docs.extend(docs)\n",
    "\n",
    "    return converted_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_validation_pdf_from_json() -> list[Document]:\n",
    "    \"\"\"\n",
    "    Return a list of Documents from the validation PDF, loaded from JSON files.\n",
    "\n",
    "    Requires AzureConverter to have been run on the PDF and saved the JSON files.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    converted_docs : list[Document]\n",
    "        The list of Documents from the validation PDF.\n",
    "    \"\"\"\n",
    "    converted_docs = []\n",
    "    file_path = Path(\"/home/tomw/unifi-pdf-llm/data/validate/SASOL Sustainability Report 2023 20-09_0_minimal_split\")\n",
    "\n",
    "    converter = AzureConverter(\n",
    "        endpoint=\"https://azureconverter.cognitiveservices.azure.com/\",\n",
    "        credential_key=AZURE_CONVERTER_KEY,\n",
    "        model_id=\"prebuilt-layout\",  # Was \"prebuilt-document\"\n",
    "    )\n",
    "\n",
    "    for fn in file_path.glob(\"*.json\"):\n",
    "        print(f\"Loading {fn}\")\n",
    "        docs = converter.convert_azure_json(file_path=fn)\n",
    "        converted_docs.extend(docs)\n",
    "\n",
    "    return converted_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading /home/tomw/unifi-pdf-llm/data/validate/SASOL Sustainability Report 2023 20-09_0_minimal_split/SASOL Sustainability Report 2023 20-09_0_minimal [7-8].json\n",
      "Loading /home/tomw/unifi-pdf-llm/data/validate/SASOL Sustainability Report 2023 20-09_0_minimal_split/SASOL Sustainability Report 2023 20-09_0_minimal [5-6].json\n",
      "Loading /home/tomw/unifi-pdf-llm/data/validate/SASOL Sustainability Report 2023 20-09_0_minimal_split/SASOL Sustainability Report 2023 20-09_0_minimal [11].json\n",
      "Loading /home/tomw/unifi-pdf-llm/data/validate/SASOL Sustainability Report 2023 20-09_0_minimal_split/SASOL Sustainability Report 2023 20-09_0_minimal [3-4].json\n",
      "Loading /home/tomw/unifi-pdf-llm/data/validate/SASOL Sustainability Report 2023 20-09_0_minimal_split/SASOL Sustainability Report 2023 20-09_0_minimal [1-2].json\n",
      "Loading /home/tomw/unifi-pdf-llm/data/validate/SASOL Sustainability Report 2023 20-09_0_minimal_split/SASOL Sustainability Report 2023 20-09_0_minimal [9-10].json\n"
     ]
    }
   ],
   "source": [
    "docs = load_validation_pdf_from_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**: Test removing the index from the tables. I don't think it adds much. Could be \n",
    "added as context to each document, and then used to recreate context of row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_documents(\n",
    "        docs: list[Document],\n",
    "        window_size: int=5\n",
    "    ) -> list[Document]:\n",
    "    \"\"\"\n",
    "    Preprocess the documents.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    docs : list[Document]\n",
    "        The documents to preprocess.\n",
    "\n",
    "    window_size : int\n",
    "        The size of the sliding window used to split the tables.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    docs : list[Document]\n",
    "        The preprocessed documents.\n",
    "    \"\"\"\n",
    "    preprocessed_docs = []\n",
    "\n",
    "    for doc in docs:\n",
    "        if doc.content_type == \"table\":\n",
    "            doc.content = clean_table_column_names(doc.content)\n",
    "            sliced_table_docs = slice_table_document(doc, window_size)\n",
    "            preprocessed_docs.extend(sliced_table_docs)\n",
    "        else:\n",
    "            preprocessed_docs.append(doc)\n",
    "\n",
    "    convert_tables_to_markdown(preprocessed_docs)\n",
    "\n",
    "    return preprocessed_docs\n",
    "\n",
    "\n",
    "def clean_table_column_names(df: pd.DataFrame, replace: str=' - ') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Return a DataFrame with newlines removed from column headers.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.Dataframe\n",
    "        The DataFrame to clean.\n",
    "\n",
    "    replace: str\n",
    "        The string to replace newlines with.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pd.Dataframe\n",
    "        The dataframe with newlines removed from column headers.\n",
    "    \"\"\"\n",
    "    df.columns = df.columns.str.replace('\\n', replace)\n",
    "    return df\n",
    "\n",
    "\n",
    "def slice_table_document(doc: Document, window_size: int=5) -> list[Document]:\n",
    "    \"\"\"\n",
    "    Return a list of documents, each containing a table with `window_size` rows.\n",
    "\n",
    "    A sliding window approach is used to split the table into smaller tables. The\n",
    "    returned documents have the same metadata as the original document, except for\n",
    "    the content and id.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc : Document\n",
    "        Document with content_type \"table\".\n",
    "\n",
    "    window_size : int\n",
    "        The size of the sliding window.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    docs : list[Document]\n",
    "        A list of documents, each one containing a table with `window_size` rows.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If the document does not contain a table.\n",
    "    \"\"\"\n",
    "    if doc.content_type != \"table\":\n",
    "        raise ValueError(\"The document does not contain a table.\")\n",
    "\n",
    "    tables = _sliding_window(doc.content, window_size)\n",
    "    docs = []\n",
    "    for table in tables:\n",
    "        new_doc = Document(content=table)\n",
    "        for attr, value in doc.__dict__.items():\n",
    "            if attr not in [\"content\", \"id\"]:\n",
    "                setattr(new_doc, attr, value)\n",
    "        docs.append(new_doc)\n",
    "\n",
    "    return docs\n",
    "\n",
    "\n",
    "def _sliding_window(df: pd.DataFrame, window_size: int) -> list[pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Return a list of DataFrames, each containing a window of the original DataFrame.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame to split.\n",
    "\n",
    "    window_size : int\n",
    "        The size of the sliding window.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tables : list[pandas.DataFrame]\n",
    "        A list of DataFrames, each containing a window of the original DataFrame.\n",
    "    \"\"\"\n",
    "    tables = [df.iloc[i:i+window_size] for i in range(len(df) - window_size + 1)]\n",
    "\n",
    "    return tables\n",
    "\n",
    "\n",
    "def convert_tables_to_markdown(docs: list[Document]) -> None:\n",
    "    \"\"\"\n",
    "    Convert tables to markdown format in place.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    docs : List[Document]\n",
    "        List of Documents, some of which may have `content_type` 'table'.\n",
    "    \"\"\"\n",
    "    for doc in docs:\n",
    "        if doc.content_type == \"table\":\n",
    "            _convert_table_to_markdown(doc)\n",
    "\n",
    "\n",
    "def _convert_table_to_markdown(doc: Document) -> None:\n",
    "    \"\"\"\n",
    "    Convert table to markdown format in place.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc : Document\n",
    "        Document with `content_type` table.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If `doc.content_type` is not \"table\".\n",
    "    \"\"\"\n",
    "    if doc.content_type != \"table\":\n",
    "        raise ValueError(f\"Document content_type must be 'table', not '{doc.content_type}'\")\n",
    "\n",
    "    table = doc.content\n",
    "    markdown_table = table.to_markdown(tablefmt=\"github\")\n",
    "\n",
    "    doc.content = markdown_table\n",
    "    doc.content_type = \"text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 806\n",
      "\n",
      "|    | Sasol in Society - Spend   | 2023 - Rm   | 2022 - Rm   | 2021 - Rm   |   2020 - Rm | LOA 2023   | Footnote   |\n",
      "|----|----------------------------|-------------|-------------|-------------|-------------|------------|------------|\n",
      "| 24 | Sasolburg                  | 1 360       | 1 366       | 1 586       |        1440 |            |            |\n"
     ]
    }
   ],
   "source": [
    "docs = preprocess_documents(docs, window_size=1)\n",
    "\n",
    "print(f\"Number of documents: {len(docs)}\\n\")\n",
    "\n",
    "print(docs[24].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try to use other document stores (e.g. FAISS).\n",
    "\n",
    "document_store = InMemoryDocumentStore(embedding_dim=384)\n",
    "\n",
    "document_store.delete_documents()\n",
    "document_store.write_documents(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 24/24 [00:00<00:00, 38.67it/s]ocs/s]\n",
      "Documents Processed: 10000 docs [00:00, 15564.22 docs/s]       \n"
     ]
    }
   ],
   "source": [
    "# TODO: I'm not sure what OpenAI embedding models are available. Is it possible to use\n",
    "# their newest embedding models in Haystack v1?\n",
    "\n",
    "# TODO: Look into other (non-OpenAI) embedding models that can be used with Haystack v1.\n",
    "\n",
    "retriever = EmbeddingRetriever(\n",
    "    embedding_model=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    document_store=document_store,\n",
    "    top_k=3\n",
    ")\n",
    "\n",
    "document_store.update_embeddings(retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 208.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | Human Capital - Our people   | 2023   | 2022   | 2021   | 2020   | LoA 2023   | Footnote   |\n",
      "|----|------------------------------|--------|--------|--------|--------|------------|------------|\n",
      "|  1 | Permanent employees          | 28 657 | 28 279 | 28 725 |        |            |            |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing the retriever\n",
    "\n",
    "retrieved_tables = retriever.retrieve(\"What was the number of permanent employees 2021?\", top_k=3)\n",
    "\n",
    "# Get highest scored table\n",
    "print(retrieved_tables[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 168.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | Human Capital - Our people               | 2023   |   2022 | 2021   | 2020   | LoA 2023   | Footnote   |\n",
      "|----|------------------------------------------|--------|--------|--------|--------|------------|------------|\n",
      "| 43 | Employee and service provider fatalities | I      |      1 |        |        |            |            |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing the retriever\n",
    "\n",
    "retrieved_tables = retriever.retrieve(\"What was the Number of fatalities in the year 2023?\", top_k=3)\n",
    "\n",
    "# Get highest scored table\n",
    "print(retrieved_tables[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 124.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | Sasol in Society - Spend   | 2023 - Rm   | 2022 - Rm   | 2021 - Rm   | 2020 - Rm   | LOA 2023   | Footnote   |\n",
      "|----|----------------------------|-------------|-------------|-------------|-------------|------------|------------|\n",
      "| 16 | Black-owned spend          | 41 700      | 33 600      | 23 800      |             |            |            |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing the retriever\n",
    "\n",
    "retrieved_tables = retriever.retrieve(\"Black-owned spend\", top_k=5)\n",
    "\n",
    "# Get highest scored table\n",
    "print(retrieved_tables[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_prompt = PromptTemplate(\n",
    "    prompt=\"\"\"Use the following pieces of context to answer the question at the end.\n",
    "              The context may be text or a markdown table.\n",
    "              Just retrieve the answer from the context. Please don't do any unit conversion.\n",
    "              If you don't know the answer, please return 'None' for the answer and unit.\n",
    "              Do not return any words other than 'Answer' and 'Unit' in the answer.\n",
    "              Please return the answer in the format 'Answer: <number or None>, Unit: <unit or None>'.\n",
    "\n",
    "              \\n\\n Context: {join(documents)} \\n\\n Question: {query}? {append} \\n\\n Answer:\"\"\",\n",
    "    output_parser=AnswerParser(),\n",
    ")\n",
    "\n",
    "generation_node = PromptNode(\n",
    "    model_name_or_path=\"gpt-3.5-turbo-1106\",  # Using 'gpt-3.5-turbo-1106' as it has a larger context window.\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    default_prompt_template=rag_prompt,\n",
    "    output_variable=\"generated_answer\",\n",
    "    model_kwargs={\"temperature\": 0}  # It doesn't seem that the `temperature` parameter is having any effect. Seems like a bug. Might work in haystack 2.0.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_node_2 = PromptNode(\n",
    "    model_name_or_path=\"gpt-3.5-turbo-1106\",  # Using 'gpt-3.5-turbo-1106' as it has a larger context window.\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    model_kwargs={\"temperature\": 0}  # It doesn't seem that the `temperature` parameter is having any effect. Seems like a bug. Might work in haystack 2.0.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The capital of France is Paris.']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation_node_2(\"What is the capital of France?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneratedAnswerParser(BaseComponent):\n",
    "    \"\"\"\n",
    "    Parse the output returned by the generation node.\n",
    "\n",
    "    The output is expected to be in the format \"Answer: <number or None>, Unit: <unit or None>\".\n",
    "    \"\"\"\n",
    "    outgoing_edges = 1\n",
    "\n",
    "    def run(self, generated_answer):\n",
    "        \"\"\"\n",
    "        Parse the output returned by the generation node.\n",
    "\n",
    "        The output is expected to be in the format \"Answer: <number or None>, Unit: <unit or None>\".\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        generated : list[Answer]\n",
    "            The output returned by the generation node.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dictionary containing the answer and unit.\n",
    "        \"\"\"\n",
    "        output = generated_answer[0].answer\n",
    "\n",
    "        answer, unit = output.split(\", \")\n",
    "        answer = answer.split(\": \")[1]\n",
    "        unit = unit.split(\": \")[1]\n",
    "\n",
    "        if answer == \"None\":\n",
    "            answer = None\n",
    "        else:\n",
    "            answer = answer.replace(\" \", \"\")\n",
    "            answer = answer.replace(\",\", \"\")\n",
    "            answer = int(answer)\n",
    "\n",
    "        return {\"answer\": answer, \"unit\": unit}, \"output_1\"\n",
    "\n",
    "    def run_batch(self, **kwargs):\n",
    "        # TODO: Implement batch processing.\n",
    "        pass\n",
    "\n",
    "\n",
    "gen_parser = GeneratedAnswerParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1240000']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unit conversion. TODO: Move\n",
    "\n",
    "def create_unit_conversion_prompt(value, unit, target_unit):\n",
    "    prompt=f\"\"\"You are an expert unit converter. You are aware of how to convert\n",
    "    between different units within the same system of measurement.\n",
    "    For example, 1236 million = 1236 * 1 million = 1236 * 1000000 = 1236000000.\n",
    "    For example, to convert from Rm to R, you would multiply by 1000000. This is because\n",
    "    1 Rm = 1000000 R.\n",
    "    Please return a single number as your answer. Do not elaborate or give\n",
    "    any context.\\n\\n\n",
    "\n",
    "    What is {value} {unit} in {target_unit}? \\n\\n Answer:\"\"\"\n",
    "\n",
    "    return prompt\n",
    "\n",
    "\n",
    "unit_conversion_node = PromptNode(\n",
    "    model_name_or_path=\"gpt-3.5-turbo\",\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    model_kwargs={\"temperature\": 0}  # It doesn't seem that the `temperature` parameter is having any effect. Seems like a bug. Might work in haystack 2.0.\n",
    ")\n",
    "\n",
    "query = create_unit_conversion_prompt(1.24, \"Rm\", \"R\")\n",
    "\n",
    "unit_conversion_node(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "querying_pipeline = Pipeline()\n",
    "querying_pipeline.add_node(component=retriever, name=\"retriever\", inputs=[\"Query\"])\n",
    "querying_pipeline.add_node(component=generation_node, name=\"prompt_node\", inputs=[\"retriever\"])\n",
    "querying_pipeline.add_node(component=gen_parser, name=\"gen_parser\", inputs=[\"prompt_node\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No node(s) or global parameter(s) named append found in pipeline.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mquerying_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWhat was the Black-owned spend in the year 2023?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mappend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDo not include the word \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLevel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m in the answer.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mretriever\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdebug\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_k\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprompt_node\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdebug\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgen_parser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdebug\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswer\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Unit: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munit\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/haystack/lib/python3.10/site-packages/haystack/pipelines/base.py:523\u001b[0m, in \u001b[0;36mPipeline.run\u001b[0;34m(self, query, file_paths, labels, documents, meta, params, debug)\u001b[0m\n\u001b[1;32m    511\u001b[0m send_pipeline_event(\n\u001b[1;32m    512\u001b[0m     pipeline\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    513\u001b[0m     query\u001b[38;5;241m=\u001b[39mquery,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[1;32m    520\u001b[0m )\n\u001b[1;32m    522\u001b[0m \u001b[38;5;66;03m# validate the node names\u001b[39;00m\n\u001b[0;32m--> 523\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_node_names_in_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m root_node \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_node\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m root_node:\n",
      "File \u001b[0;32m~/miniconda3/envs/haystack/lib/python3.10/site-packages/haystack/pipelines/base.py:2448\u001b[0m, in \u001b[0;36mPipeline._validate_node_names_in_params\u001b[0;34m(self, params)\u001b[0m\n\u001b[1;32m   2445\u001b[0m invalid_keys \u001b[38;5;241m=\u001b[39m [key \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m not_a_node \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m valid_global_params]\n\u001b[1;32m   2447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m invalid_keys:\n\u001b[0;32m-> 2448\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2449\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo node(s) or global parameter(s) named \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(invalid_keys)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m found in pipeline.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2450\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: No node(s) or global parameter(s) named append found in pipeline."
     ]
    }
   ],
   "source": [
    "output = querying_pipeline.run(\n",
    "    query=\"What was the Black-owned spend in the year 2023?\",\n",
    "    params={\n",
    "        \"append\": \"Do not include the word 'Level' in the answer.\",\n",
    "        \"retriever\": {\"debug\": True, \"top_k\": 5},\n",
    "        \"prompt_node\": {\"debug\": True},\n",
    "        \"gen_parser\": {\"debug\": True},\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Answer: {output['answer']}, Unit: {output['unit']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'retriever': {'input': {'root_node': 'Query',\n",
       "   'query': 'What was the Black-owned spend in the year 2023?',\n",
       "   'top_k': 5,\n",
       "   'debug': True},\n",
       "  'output': {'documents': [<Document: {'content': '|    | Human Capital - Our people                | 2023   |   2022 |   2021 | 2020   | LoA 2023   |   Footnote |\\n|----|-------------------------------------------|--------|--------|--------|--------|------------|------------|\\n| 52 | Investment in black employees (R million) | 724,64 |    698 |    884 | 748,00 |            |          6 |', 'content_type': 'text', 'score': 0.501289664925134, 'meta': {'preceding_context': '- Significant fires, explosions and releases\\n2\\n6', 'following_context': '- Major fires, explosions and releases\\n-\\n-', 'page': 2}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ad9e935dda72423edad23396d1eaa0d6'}>,\n",
       "    <Document: {'content': '|    | Natural Capital - Our environment      |   2023 |   2022 |   2021 |   2020 | LoA 2023   | Footnote   |\\n|----|----------------------------------------|--------|--------|--------|--------|------------|------------|\\n| 54 | Broad-Based Black Economic Empowerment |   2023 |   2022 |   2021 |   2020 |            |            |', 'content_type': 'text', 'score': 0.5012002830992816, 'meta': {'preceding_context': 'Mozambique\\nOther strategic business units and Functions\\n2,32', 'following_context': 'CHEMICALS\\n290\\n290,00', 'page': 1}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '6babb8eee47d41beb161d288d6a77565'}>,\n",
       "    <Document: {'content': '|    | Sasol in Society - Spend   | 2023 - Rm   | 2022 - Rm   | 2021 - Rm   | 2020 - Rm   | LOA 2023   | Footnote   |\\n|----|----------------------------|-------------|-------------|-------------|-------------|------------|------------|\\n| 17 | Black-owned women spend    | 28 500      | 21 600      | 15 800      |             |            |            |', 'content_type': 'text', 'score': 0.5011286273056463, 'meta': {'preceding_context': 'DATA AND ASSURANCE\\nANNEXURES\\nPERFORMANCE DATA CONTINUED', 'following_context': 'Secunda\\n13 903\\n14 399', 'page': 1}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c85916ccc6c6e24864bdb9db90b6f143'}>,\n",
       "    <Document: {'content': '|    | Sasol in Society - Spend   | 2023 - Rm   | 2022 - Rm   | 2021 - Rm   | 2020 - Rm   | LOA 2023   | Footnote   |\\n|----|----------------------------|-------------|-------------|-------------|-------------|------------|------------|\\n| 16 | Black-owned spend          | 41 700      | 33 600      | 23 800      |             |            |            |', 'content_type': 'text', 'score': 0.5011281499493787, 'meta': {'preceding_context': 'DATA AND ASSURANCE\\nANNEXURES\\nPERFORMANCE DATA CONTINUED', 'following_context': 'Secunda\\n13 903\\n14 399', 'page': 1}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '770b8226830ea002d2d74259c6fe0404'}>,\n",
       "    <Document: {'content': '|    | Sasol in Society - Spend   |   2023 - Rm | 2022 - Rm   | 2021 - Rm   | 2020 - Rm   | LOA 2023   | Footnote   |\\n|----|----------------------------|-------------|-------------|-------------|-------------|------------|------------|\\n|  5 | North America              |          24 | 15,2        | 9,7         |             |            |            |', 'content_type': 'text', 'score': 0.501049340987386, 'meta': {'preceding_context': 'DATA AND ASSURANCE\\nANNEXURES\\nPERFORMANCE DATA CONTINUED', 'following_context': 'Secunda\\n13 903\\n14 399', 'page': 1}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'fc7ec4c6224ae878e21d62d3085ce5f9'}>]},\n",
       "  'exec_time_ms': 54.72},\n",
       " 'prompt_node': {'input': {'documents': [<Document: {'content': '|    | Human Capital - Our people                | 2023   |   2022 |   2021 | 2020   | LoA 2023   |   Footnote |\\n|----|-------------------------------------------|--------|--------|--------|--------|------------|------------|\\n| 52 | Investment in black employees (R million) | 724,64 |    698 |    884 | 748,00 |            |          6 |', 'content_type': 'text', 'score': 0.501289664925134, 'meta': {'preceding_context': '- Significant fires, explosions and releases\\n2\\n6', 'following_context': '- Major fires, explosions and releases\\n-\\n-', 'page': 2}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ad9e935dda72423edad23396d1eaa0d6'}>,\n",
       "    <Document: {'content': '|    | Natural Capital - Our environment      |   2023 |   2022 |   2021 |   2020 | LoA 2023   | Footnote   |\\n|----|----------------------------------------|--------|--------|--------|--------|------------|------------|\\n| 54 | Broad-Based Black Economic Empowerment |   2023 |   2022 |   2021 |   2020 |            |            |', 'content_type': 'text', 'score': 0.5012002830992816, 'meta': {'preceding_context': 'Mozambique\\nOther strategic business units and Functions\\n2,32', 'following_context': 'CHEMICALS\\n290\\n290,00', 'page': 1}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '6babb8eee47d41beb161d288d6a77565'}>,\n",
       "    <Document: {'content': '|    | Sasol in Society - Spend   | 2023 - Rm   | 2022 - Rm   | 2021 - Rm   | 2020 - Rm   | LOA 2023   | Footnote   |\\n|----|----------------------------|-------------|-------------|-------------|-------------|------------|------------|\\n| 17 | Black-owned women spend    | 28 500      | 21 600      | 15 800      |             |            |            |', 'content_type': 'text', 'score': 0.5011286273056463, 'meta': {'preceding_context': 'DATA AND ASSURANCE\\nANNEXURES\\nPERFORMANCE DATA CONTINUED', 'following_context': 'Secunda\\n13 903\\n14 399', 'page': 1}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c85916ccc6c6e24864bdb9db90b6f143'}>,\n",
       "    <Document: {'content': '|    | Sasol in Society - Spend   | 2023 - Rm   | 2022 - Rm   | 2021 - Rm   | 2020 - Rm   | LOA 2023   | Footnote   |\\n|----|----------------------------|-------------|-------------|-------------|-------------|------------|------------|\\n| 16 | Black-owned spend          | 41 700      | 33 600      | 23 800      |             |            |            |', 'content_type': 'text', 'score': 0.5011281499493787, 'meta': {'preceding_context': 'DATA AND ASSURANCE\\nANNEXURES\\nPERFORMANCE DATA CONTINUED', 'following_context': 'Secunda\\n13 903\\n14 399', 'page': 1}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '770b8226830ea002d2d74259c6fe0404'}>,\n",
       "    <Document: {'content': '|    | Sasol in Society - Spend   |   2023 - Rm | 2022 - Rm   | 2021 - Rm   | 2020 - Rm   | LOA 2023   | Footnote   |\\n|----|----------------------------|-------------|-------------|-------------|-------------|------------|------------|\\n|  5 | North America              |          24 | 15,2        | 9,7         |             |            |            |', 'content_type': 'text', 'score': 0.501049340987386, 'meta': {'preceding_context': 'DATA AND ASSURANCE\\nANNEXURES\\nPERFORMANCE DATA CONTINUED', 'following_context': 'Secunda\\n13 903\\n14 399', 'page': 1}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'fc7ec4c6224ae878e21d62d3085ce5f9'}>],\n",
       "   'query': 'What was the Black-owned spend in the year 2023?',\n",
       "   'debug': True},\n",
       "  'output': {'generated_answer': [<Answer {'answer': 'Answer: 41 700, Unit: Rm', 'type': 'generative', 'score': None, 'context': None, 'offsets_in_document': None, 'offsets_in_context': None, 'document_ids': ['ad9e935dda72423edad23396d1eaa0d6', '6babb8eee47d41beb161d288d6a77565', 'c85916ccc6c6e24864bdb9db90b6f143', '770b8226830ea002d2d74259c6fe0404', 'fc7ec4c6224ae878e21d62d3085ce5f9'], 'meta': {'prompt': \"Use the following pieces of context to answer the question at the end.\\n              The context may be text or a markdown table.\\n              Just retrieve the answer from the context. Please don't do any unit conversion.\\n              If you don't know the answer, please return 'None' for the answer and unit.\\n              Do not return any words other than 'Answer' and 'Unit' in the answer.\\n              Please return the answer in the format 'Answer: <number or None>, Unit: <unit or None>'.\\n\\n              \\n\\n Context: |    | Human Capital - Our people                | 2023   |   2022 |   2021 | 2020   | LoA 2023   |   Footnote |\\n|----|-------------------------------------------|--------|--------|--------|--------|------------|------------|\\n| 52 | Investment in black employees (R million) | 724,64 |    698 |    884 | 748,00 |            |          6 | |    | Natural Capital - Our environment      |   2023 |   2022 |   2021 |   2020 | LoA 2023   | Footnote   |\\n|----|----------------------------------------|--------|--------|--------|--------|------------|------------|\\n| 54 | Broad-Based Black Economic Empowerment |   2023 |   2022 |   2021 |   2020 |            |            | |    | Sasol in Society - Spend   | 2023 - Rm   | 2022 - Rm   | 2021 - Rm   | 2020 - Rm   | LOA 2023   | Footnote   |\\n|----|----------------------------|-------------|-------------|-------------|-------------|------------|------------|\\n| 17 | Black-owned women spend    | 28 500      | 21 600      | 15 800      |             |            |            | |    | Sasol in Society - Spend   | 2023 - Rm   | 2022 - Rm   | 2021 - Rm   | 2020 - Rm   | LOA 2023   | Footnote   |\\n|----|----------------------------|-------------|-------------|-------------|-------------|------------|------------|\\n| 16 | Black-owned spend          | 41 700      | 33 600      | 23 800      |             |            |            | |    | Sasol in Society - Spend   |   2023 - Rm | 2022 - Rm   | 2021 - Rm   | 2020 - Rm   | LOA 2023   | Footnote   |\\n|----|----------------------------|-------------|-------------|-------------|-------------|------------|------------|\\n|  5 | North America              |          24 | 15,2        | 9,7         |             |            |            | \\n\\n Question: What was the Black-owned spend in the year 2023? \\n\\n Answer:\"}}>],\n",
       "   'invocation_context': {'query': 'What was the Black-owned spend in the year 2023?',\n",
       "    'documents': [<Document: {'content': '|    | Human Capital - Our people                | 2023   |   2022 |   2021 | 2020   | LoA 2023   |   Footnote |\\n|----|-------------------------------------------|--------|--------|--------|--------|------------|------------|\\n| 52 | Investment in black employees (R million) | 724,64 |    698 |    884 | 748,00 |            |          6 |', 'content_type': 'text', 'score': 0.501289664925134, 'meta': {'preceding_context': '- Significant fires, explosions and releases\\n2\\n6', 'following_context': '- Major fires, explosions and releases\\n-\\n-', 'page': 2}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'ad9e935dda72423edad23396d1eaa0d6'}>,\n",
       "     <Document: {'content': '|    | Natural Capital - Our environment      |   2023 |   2022 |   2021 |   2020 | LoA 2023   | Footnote   |\\n|----|----------------------------------------|--------|--------|--------|--------|------------|------------|\\n| 54 | Broad-Based Black Economic Empowerment |   2023 |   2022 |   2021 |   2020 |            |            |', 'content_type': 'text', 'score': 0.5012002830992816, 'meta': {'preceding_context': 'Mozambique\\nOther strategic business units and Functions\\n2,32', 'following_context': 'CHEMICALS\\n290\\n290,00', 'page': 1}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '6babb8eee47d41beb161d288d6a77565'}>,\n",
       "     <Document: {'content': '|    | Sasol in Society - Spend   | 2023 - Rm   | 2022 - Rm   | 2021 - Rm   | 2020 - Rm   | LOA 2023   | Footnote   |\\n|----|----------------------------|-------------|-------------|-------------|-------------|------------|------------|\\n| 17 | Black-owned women spend    | 28 500      | 21 600      | 15 800      |             |            |            |', 'content_type': 'text', 'score': 0.5011286273056463, 'meta': {'preceding_context': 'DATA AND ASSURANCE\\nANNEXURES\\nPERFORMANCE DATA CONTINUED', 'following_context': 'Secunda\\n13 903\\n14 399', 'page': 1}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'c85916ccc6c6e24864bdb9db90b6f143'}>,\n",
       "     <Document: {'content': '|    | Sasol in Society - Spend   | 2023 - Rm   | 2022 - Rm   | 2021 - Rm   | 2020 - Rm   | LOA 2023   | Footnote   |\\n|----|----------------------------|-------------|-------------|-------------|-------------|------------|------------|\\n| 16 | Black-owned spend          | 41 700      | 33 600      | 23 800      |             |            |            |', 'content_type': 'text', 'score': 0.5011281499493787, 'meta': {'preceding_context': 'DATA AND ASSURANCE\\nANNEXURES\\nPERFORMANCE DATA CONTINUED', 'following_context': 'Secunda\\n13 903\\n14 399', 'page': 1}, 'id_hash_keys': ['content'], 'embedding': None, 'id': '770b8226830ea002d2d74259c6fe0404'}>,\n",
       "     <Document: {'content': '|    | Sasol in Society - Spend   |   2023 - Rm | 2022 - Rm   | 2021 - Rm   | 2020 - Rm   | LOA 2023   | Footnote   |\\n|----|----------------------------|-------------|-------------|-------------|-------------|------------|------------|\\n|  5 | North America              |          24 | 15,2        | 9,7         |             |            |            |', 'content_type': 'text', 'score': 0.501049340987386, 'meta': {'preceding_context': 'DATA AND ASSURANCE\\nANNEXURES\\nPERFORMANCE DATA CONTINUED', 'following_context': 'Secunda\\n13 903\\n14 399', 'page': 1}, 'id_hash_keys': ['content'], 'embedding': None, 'id': 'fc7ec4c6224ae878e21d62d3085ce5f9'}>],\n",
       "    'generated_answer': [<Answer {'answer': 'Answer: 41 700, Unit: Rm', 'type': 'generative', 'score': None, 'context': None, 'offsets_in_document': None, 'offsets_in_context': None, 'document_ids': ['ad9e935dda72423edad23396d1eaa0d6', '6babb8eee47d41beb161d288d6a77565', 'c85916ccc6c6e24864bdb9db90b6f143', '770b8226830ea002d2d74259c6fe0404', 'fc7ec4c6224ae878e21d62d3085ce5f9'], 'meta': {'prompt': \"Use the following pieces of context to answer the question at the end.\\n              The context may be text or a markdown table.\\n              Just retrieve the answer from the context. Please don't do any unit conversion.\\n              If you don't know the answer, please return 'None' for the answer and unit.\\n              Do not return any words other than 'Answer' and 'Unit' in the answer.\\n              Please return the answer in the format 'Answer: <number or None>, Unit: <unit or None>'.\\n\\n              \\n\\n Context: |    | Human Capital - Our people                | 2023   |   2022 |   2021 | 2020   | LoA 2023   |   Footnote |\\n|----|-------------------------------------------|--------|--------|--------|--------|------------|------------|\\n| 52 | Investment in black employees (R million) | 724,64 |    698 |    884 | 748,00 |            |          6 | |    | Natural Capital - Our environment      |   2023 |   2022 |   2021 |   2020 | LoA 2023   | Footnote   |\\n|----|----------------------------------------|--------|--------|--------|--------|------------|------------|\\n| 54 | Broad-Based Black Economic Empowerment |   2023 |   2022 |   2021 |   2020 |            |            | |    | Sasol in Society - Spend   | 2023 - Rm   | 2022 - Rm   | 2021 - Rm   | 2020 - Rm   | LOA 2023   | Footnote   |\\n|----|----------------------------|-------------|-------------|-------------|-------------|------------|------------|\\n| 17 | Black-owned women spend    | 28 500      | 21 600      | 15 800      |             |            |            | |    | Sasol in Society - Spend   | 2023 - Rm   | 2022 - Rm   | 2021 - Rm   | 2020 - Rm   | LOA 2023   | Footnote   |\\n|----|----------------------------|-------------|-------------|-------------|-------------|------------|------------|\\n| 16 | Black-owned spend          | 41 700      | 33 600      | 23 800      |             |            |            | |    | Sasol in Society - Spend   |   2023 - Rm | 2022 - Rm   | 2021 - Rm   | 2020 - Rm   | LOA 2023   | Footnote   |\\n|----|----------------------------|-------------|-------------|-------------|-------------|------------|------------|\\n|  5 | North America              |          24 | 15,2        | 9,7         |             |            |            | \\n\\n Question: What was the Black-owned spend in the year 2023? \\n\\n Answer:\"}}>],\n",
       "    'prompts': [\"Use the following pieces of context to answer the question at the end.\\n              The context may be text or a markdown table.\\n              Just retrieve the answer from the context. Please don't do any unit conversion.\\n              If you don't know the answer, please return 'None' for the answer and unit.\\n              Do not return any words other than 'Answer' and 'Unit' in the answer.\\n              Please return the answer in the format 'Answer: <number or None>, Unit: <unit or None>'.\\n\\n              \\n\\n Context: |    | Human Capital - Our people                | 2023   |   2022 |   2021 | 2020   | LoA 2023   |   Footnote |\\n|----|-------------------------------------------|--------|--------|--------|--------|------------|------------|\\n| 52 | Investment in black employees (R million) | 724,64 |    698 |    884 | 748,00 |            |          6 | |    | Natural Capital - Our environment      |   2023 |   2022 |   2021 |   2020 | LoA 2023   | Footnote   |\\n|----|----------------------------------------|--------|--------|--------|--------|------------|------------|\\n| 54 | Broad-Based Black Economic Empowerment |   2023 |   2022 |   2021 |   2020 |            |            | |    | Sasol in Society - Spend   | 2023 - Rm   | 2022 - Rm   | 2021 - Rm   | 2020 - Rm   | LOA 2023   | Footnote   |\\n|----|----------------------------|-------------|-------------|-------------|-------------|------------|------------|\\n| 17 | Black-owned women spend    | 28 500      | 21 600      | 15 800      |             |            |            | |    | Sasol in Society - Spend   | 2023 - Rm   | 2022 - Rm   | 2021 - Rm   | 2020 - Rm   | LOA 2023   | Footnote   |\\n|----|----------------------------|-------------|-------------|-------------|-------------|------------|------------|\\n| 16 | Black-owned spend          | 41 700      | 33 600      | 23 800      |             |            |            | |    | Sasol in Society - Spend   |   2023 - Rm | 2022 - Rm   | 2021 - Rm   | 2020 - Rm   | LOA 2023   | Footnote   |\\n|----|----------------------------|-------------|-------------|-------------|-------------|------------|------------|\\n|  5 | North America              |          24 | 15,2        | 9,7         |             |            |            | \\n\\n Question: What was the Black-owned spend in the year 2023? \\n\\n Answer:\"]}},\n",
       "  'runtime': {'prompts_used': [\"Use the following pieces of context to answer the question at the end.\\n              The context may be text or a markdown table.\\n              Just retrieve the answer from the context. Please don't do any unit conversion.\\n              If you don't know the answer, please return 'None' for the answer and unit.\\n              Do not return any words other than 'Answer' and 'Unit' in the answer.\\n              Please return the answer in the format 'Answer: <number or None>, Unit: <unit or None>'.\\n\\n              \\n\\n Context: |    | Human Capital - Our people                | 2023   |   2022 |   2021 | 2020   | LoA 2023   |   Footnote |\\n|----|-------------------------------------------|--------|--------|--------|--------|------------|------------|\\n| 52 | Investment in black employees (R million) | 724,64 |    698 |    884 | 748,00 |            |          6 | |    | Natural Capital - Our environment      |   2023 |   2022 |   2021 |   2020 | LoA 2023   | Footnote   |\\n|----|----------------------------------------|--------|--------|--------|--------|------------|------------|\\n| 54 | Broad-Based Black Economic Empowerment |   2023 |   2022 |   2021 |   2020 |            |            | |    | Sasol in Society - Spend   | 2023 - Rm   | 2022 - Rm   | 2021 - Rm   | 2020 - Rm   | LOA 2023   | Footnote   |\\n|----|----------------------------|-------------|-------------|-------------|-------------|------------|------------|\\n| 17 | Black-owned women spend    | 28 500      | 21 600      | 15 800      |             |            |            | |    | Sasol in Society - Spend   | 2023 - Rm   | 2022 - Rm   | 2021 - Rm   | 2020 - Rm   | LOA 2023   | Footnote   |\\n|----|----------------------------|-------------|-------------|-------------|-------------|------------|------------|\\n| 16 | Black-owned spend          | 41 700      | 33 600      | 23 800      |             |            |            | |    | Sasol in Society - Spend   |   2023 - Rm | 2022 - Rm   | 2021 - Rm   | 2020 - Rm   | LOA 2023   | Footnote   |\\n|----|----------------------------|-------------|-------------|-------------|-------------|------------|------------|\\n|  5 | North America              |          24 | 15,2        | 9,7         |             |            |            | \\n\\n Question: What was the Black-owned spend in the year 2023? \\n\\n Answer:\"]},\n",
       "  'exec_time_ms': 723.35},\n",
       " 'gen_parser': {'input': {'generated_answer': [<Answer {'answer': 'Answer: 41 700, Unit: Rm', 'type': 'generative', 'score': None, 'context': None, 'offsets_in_document': None, 'offsets_in_context': None, 'document_ids': ['ad9e935dda72423edad23396d1eaa0d6', '6babb8eee47d41beb161d288d6a77565', 'c85916ccc6c6e24864bdb9db90b6f143', '770b8226830ea002d2d74259c6fe0404', 'fc7ec4c6224ae878e21d62d3085ce5f9'], 'meta': {'prompt': \"Use the following pieces of context to answer the question at the end.\\n              The context may be text or a markdown table.\\n              Just retrieve the answer from the context. Please don't do any unit conversion.\\n              If you don't know the answer, please return 'None' for the answer and unit.\\n              Do not return any words other than 'Answer' and 'Unit' in the answer.\\n              Please return the answer in the format 'Answer: <number or None>, Unit: <unit or None>'.\\n\\n              \\n\\n Context: |    | Human Capital - Our people                | 2023   |   2022 |   2021 | 2020   | LoA 2023   |   Footnote |\\n|----|-------------------------------------------|--------|--------|--------|--------|------------|------------|\\n| 52 | Investment in black employees (R million) | 724,64 |    698 |    884 | 748,00 |            |          6 | |    | Natural Capital - Our environment      |   2023 |   2022 |   2021 |   2020 | LoA 2023   | Footnote   |\\n|----|----------------------------------------|--------|--------|--------|--------|------------|------------|\\n| 54 | Broad-Based Black Economic Empowerment |   2023 |   2022 |   2021 |   2020 |            |            | |    | Sasol in Society - Spend   | 2023 - Rm   | 2022 - Rm   | 2021 - Rm   | 2020 - Rm   | LOA 2023   | Footnote   |\\n|----|----------------------------|-------------|-------------|-------------|-------------|------------|------------|\\n| 17 | Black-owned women spend    | 28 500      | 21 600      | 15 800      |             |            |            | |    | Sasol in Society - Spend   | 2023 - Rm   | 2022 - Rm   | 2021 - Rm   | 2020 - Rm   | LOA 2023   | Footnote   |\\n|----|----------------------------|-------------|-------------|-------------|-------------|------------|------------|\\n| 16 | Black-owned spend          | 41 700      | 33 600      | 23 800      |             |            |            | |    | Sasol in Society - Spend   |   2023 - Rm | 2022 - Rm   | 2021 - Rm   | 2020 - Rm   | LOA 2023   | Footnote   |\\n|----|----------------------------|-------------|-------------|-------------|-------------|------------|------------|\\n|  5 | North America              |          24 | 15,2        | 9,7         |             |            |            | \\n\\n Question: What was the Black-owned spend in the year 2023? \\n\\n Answer:\"}}>],\n",
       "   'debug': True},\n",
       "  'output': {'answer': 41700, 'unit': 'Rm'},\n",
       "  'exec_time_ms': 0.15}}"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Write function to convert the answer to a more human-readable format.\n",
    "# In particular, the markdown tables aren't very readable as a single line of text.\n",
    "\n",
    "output[\"_debug\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `gpt-3.5-turbo` model has a context window of 4,096 tokens. As a result, my prompt is often\n",
    "being truncated so that the prompt length and answer length (100 tokens) fit within the max token\n",
    "limit. The updated GPT-3.5 model (`gpt-3.5-turbo-0125`) has a larger context window of \n",
    "16,385 tokens. Would be good to use this, if possible (may require using haystack 2.0)\n",
    "The slightly older GPT-3.5 model `gpt-3.5-turbo-1106` has a larger context window and is available \n",
    "with haystack 1.0. I'll use this for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 55.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Testing appending additional instructions to the query.\n",
    "\n",
    "output = querying_pipeline.run(\n",
    "    query=\"What was the B-BBEE status in the year 2021? Do not include the word 'Level' in the answer.\",\n",
    "    params={\n",
    "        \"retriever\": {\"debug\": True},\n",
    "        \"prompt_node\": {\"debug\": True},\n",
    "        \"gen_parser\": {\"debug\": True},\n",
    "    }\n",
    ")\n",
    "\n",
    "print(output['answer'])\n",
    "print(output['unit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 39.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3869\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "output = querying_pipeline.run(\n",
    "    query=\"What was the Employee turnover in the year 2021?\",\n",
    "    params={\n",
    "        \"retriever\": {\"debug\": True},\n",
    "        \"prompt_node\": {\"debug\": True},\n",
    "        \"gen_parser\": {\"debug\": True},\n",
    "    }\n",
    ")\n",
    "\n",
    "print(output['answer'])\n",
    "print(output['unit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should there be two pipelines - one for queries which may require unit conversion,\n",
    "and another for queries that don't? For example, when retrieving the employee turnover,\n",
    "the unit should always be 'None'. So why ask the model to try and retrieve this - want \n",
    "to make it easier for the model when possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "querying_pipeline.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working very well. Only issue I have seen so far is not being able to answer \"What was the \n",
    "GHG Scope 2 emissions in the year 2021?\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function querying pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want more control over the pipeline. For example, I want the retriever to be called\n",
    "with only the metric description (not the year), and for some AMKEYs I want to append \n",
    "additional instructions to the question. \n",
    "\n",
    "A class based solution might work well. Could be initilaised with the list of documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AMKEY                                     ActivityMetric\n",
      "0      3              Advisory fees as per income statement\n",
      "1      6  Air emissions of the following pollutants: (1) CO\n",
      "2      7  Air emissions of the following pollutants: (2)...\n",
      "3      8  Air emissions of the following pollutants: (3)...\n",
      "4      9  Air emissions of the following pollutants: (4)...\n",
      "B-BBEE Scorecard Level\n"
     ]
    }
   ],
   "source": [
    "amkey_to_metric = pd.read_csv(AMKEY_TO_METRIC_PATH)\n",
    "print(amkey_to_metric.head())\n",
    "\n",
    "# Retrieve the metric for AMKEY=3\n",
    "metric = amkey_to_metric[amkey_to_metric[\"AMKEY\"] == 49][\"ActivityMetric\"].item()\n",
    "print(metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AMKEY   Group                                     ActivityMetric  \\\n",
      "0      7  Impala  Air emissions of the following pollutants: (2)...   \n",
      "1      7   Sasol  Air emissions of the following pollutants: (2)...   \n",
      "2      8   Sasol  Air emissions of the following pollutants: (3)...   \n",
      "3      8     Ssw  Air emissions of the following pollutants: (3)...   \n",
      "4      8  Impala  Air emissions of the following pollutants: (3)...   \n",
      "\n",
      "                            ClientMetric  \n",
      "0                     Total indirect Nox  \n",
      "1       Nitrogen oxides (NOx) (kilotons)  \n",
      "2       Sulphur oxides (SOx ) (kilotons)  \n",
      "3                          SO2 emissions  \n",
      "4  Total direct SO2 + Total indirect SO2  \n"
     ]
    }
   ],
   "source": [
    "amkey_to_synonym = pd.read_csv(AMKEY_TO_SYNONYM_PATH)\n",
    "print(amkey_to_synonym.head())\n",
    "\n",
    "# Retrieve the metric for AMKEY=7 and Group=Impala\n",
    "metric = amkey_to_synonym[(amkey_to_synonym[\"AMKEY\"] == 49) & (amkey_to_synonym[\"Group\"] == \"Sasol\")][\"ClientMetric\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17    B-BBEE verification certificate\n",
       "Name: ClientMetric, dtype: object"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No metric found.\n"
     ]
    }
   ],
   "source": [
    "# Check if metric is empty\n",
    "if metric.empty:\n",
    "    print(\"No metric found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   AMKEY                                     ActivityMetric  Unit\n",
      "0      3              Advisory fees as per income statement  rand\n",
      "1      6  Air emissions of the following pollutants: (1) CO   NaN\n",
      "2      7  Air emissions of the following pollutants: (2)...   NaN\n",
      "3      8  Air emissions of the following pollutants: (3)...   NaN\n",
      "4      9  Air emissions of the following pollutants: (4)...   NaN\n"
     ]
    }
   ],
   "source": [
    "amkey_to_unit = pd.read_csv(AMKEY_TO_UNIT_PATH)\n",
    "print(amkey_to_unit.head())\n",
    "\n",
    "unit = amkey_to_unit[amkey_to_unit[\"AMKEY\"] == 6][\"Unit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/haystack/lib/python3.10/site-packages/pandas/core/indexes/base.py:3802\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3801\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3802\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3803\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:153\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:182\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2606\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:2630\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[179], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43munit\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/haystack/lib/python3.10/site-packages/pandas/core/series.py:1111\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1113\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1114\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/miniconda3/envs/haystack/lib/python3.10/site-packages/pandas/core/series.py:1227\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1224\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1227\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1230\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/miniconda3/envs/haystack/lib/python3.10/site-packages/pandas/core/indexes/base.py:3809\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3805\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3806\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3807\u001b[0m     ):\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3809\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3810\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3811\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3812\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "unit[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    False\n",
       "Name: Unit, dtype: bool"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unit == 'NaN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryPipeline2:\n",
    "    def __init__(\n",
    "            self,\n",
    "            docs: list[Document]\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Initalise the components of the query pipeline.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        docs : list[Document]\n",
    "            The documents to provide context for the queries.\n",
    "        \"\"\"\n",
    "        self.docs = docs\n",
    "\n",
    "        self.document_store = None\n",
    "        self.retriever = None\n",
    "        self.generation_llm = None\n",
    "\n",
    "        self.initialise_document_store()\n",
    "        self.initialise_retriever()\n",
    "        self.initialise_generation_llm()\n",
    "\n",
    "    def initialise_document_store(self):\n",
    "        logger.info(\"Initialising document store\")\n",
    "        self.document_store = InMemoryDocumentStore(embedding_dim=384)\n",
    "        self.document_store.delete_documents()\n",
    "        self.document_store.write_documents(docs)\n",
    "\n",
    "    def initialise_retriever(self, top_k=3):\n",
    "        logger.info(\"Initialising retriever\")\n",
    "        self.retriever = EmbeddingRetriever(\n",
    "            embedding_model=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "            document_store=self.document_store,\n",
    "            top_k=top_k\n",
    "        )\n",
    "        self.document_store.update_embeddings(retriever=self.retriever)\n",
    "\n",
    "    def initialise_generation_llm(self):\n",
    "        logger.info(\"Initialising generation LLM\")\n",
    "        self.generation_llm = PromptNode(\n",
    "            model_name_or_path=\"gpt-3.5-turbo-1106\",\n",
    "            api_key=OPENAI_API_KEY,\n",
    "            model_kwargs={\"temperature\": 0}\n",
    "        )\n",
    "\n",
    "    def query(self, metric: str, year: int):\n",
    "        \"\"\"\n",
    "        Return the value of a metric for a given year.\n",
    "\n",
    "        Uses retrieval augmented generation to answer the query.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        metric : str\n",
    "            The metric to retrieve.\n",
    "\n",
    "        year : int\n",
    "            The year to retrieve the metric for.\n",
    "        \"\"\"\n",
    "        context_documents = self.retriever.retrieve(metric)\n",
    "\n",
    "        prompt = self._create_generation_prompt(metric, year, context_documents)\n",
    "\n",
    "        answer = self.generation_llm(prompt)[0]\n",
    "\n",
    "        value, unit = self.parse_answer(answer)\n",
    "\n",
    "        return value, unit\n",
    "\n",
    "    def _create_generation_prompt(\n",
    "            self,\n",
    "            metric: str,\n",
    "            year: int,\n",
    "            docs: list[Document]\n",
    "        )-> str:\n",
    "        \"\"\"\n",
    "        Create a prompt for the generation LLM.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        metric : str\n",
    "            The metric to retrieve.\n",
    "\n",
    "        year : int\n",
    "            The year to retrieve the metric for.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        prompt : str\n",
    "            The prompt for the generation LLM.\n",
    "        \"\"\"\n",
    "        query = f\"What was the {metric} in the year {year}?\"\n",
    "\n",
    "        # TODO: Generalise this to other metrics.\n",
    "        if metric in [\"B-BBEE status\", \"B-BBEE scorecard level\"]:\n",
    "            query += \" Do not include the word 'Level' in the answer.\"\n",
    "\n",
    "        context = \"\\n\\n\".join([doc.content for doc in docs])\n",
    "\n",
    "        prompt = f\"\"\"Use the following pieces of context to answer the question at the end.\n",
    "                    The context may be text or a markdown table.\n",
    "                    Just retrieve the answer from the context. Please don't do any unit conversion.\n",
    "                    If you don't know the answer, please return 'None' for the answer and unit.\n",
    "                    Do not return any words other than 'Answer' and 'Unit' in the answer.\n",
    "                    Please return the answer in the format 'Answer: <number or None>, Unit: <unit or None>'.\n",
    "\n",
    "                    \\n\\n Context: {context} \\n\\n Question: {query} \\n\\n Answer:\"\"\"\n",
    "\n",
    "        return prompt\n",
    "\n",
    "    def parse_answer(self, answer: str) -> tuple[int | None, str | None]:\n",
    "        \"\"\"\n",
    "        Parse the answer returned by the generation LLM.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        answer : str\n",
    "            The answer returned by the generation LLM. This is expected to be in the\n",
    "            format \"Answer: <number or None>, Unit: <unit or None>\".\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        value : int | None\n",
    "            The value from the answer.\n",
    "\n",
    "        unit : str | None\n",
    "            The unit from the answer.\n",
    "        \"\"\"\n",
    "        value, unit = answer.split(\", \")\n",
    "        value = value.split(\": \")[1]\n",
    "        unit = unit.split(\": \")[1]\n",
    "\n",
    "        if value == \"None\":\n",
    "            value = None\n",
    "        else:\n",
    "            value = value.replace(\" \", \"\")\n",
    "            value = value.replace(\",\", \"\")\n",
    "            value = int(value)\n",
    "\n",
    "        return value, unit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-18 22:03:20.107 | INFO     | __main__:initialise_document_store:25 - Initialising document store\n",
      "2024-02-18 22:03:20.115 | INFO     | __main__:initialise_retriever:31 - Initialising retriever\n",
      "Batches: 100%|██████████| 24/24 [00:00<00:00, 35.90it/s]ocs/s]\n",
      "Documents Processed: 10000 docs [00:00, 14478.99 docs/s]       \n",
      "2024-02-18 22:03:22.888 | INFO     | __main__:initialise_generation_llm:40 - Initialising generation LLM\n"
     ]
    }
   ],
   "source": [
    "query_class = QueryPipeline2(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 208.05it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(41700, 'Rm')"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_class.query(\"Black-owned spend\", 2023)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation of querying pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_FILE = Path(\"/home/tomw/unifi-pdf-llm/data/validate/rag_esg_metric_validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_rag(docs: list[Document]) -> pd.DataFrame:\n",
    "    validation_df = pd.read_csv(VALIDATION_FILE)\n",
    "    results_df = validation_df.copy(deep=True)\n",
    "    query_class = QueryPipeline2(docs)\n",
    "\n",
    "    # Add row to results_df for the generated answer\n",
    "    results_df[\"Generated\"] = None\n",
    "\n",
    "    for idx, row in validation_df.iterrows():\n",
    "        year = row[\"Year\"]\n",
    "        metric = row[\"Metric\"]\n",
    "\n",
    "        value, _ = query_class.query(metric, year)\n",
    "\n",
    "        results_df.at[idx, \"Generated\"] = value\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-18 22:04:59.204 | INFO     | __main__:initialise_document_store:25 - Initialising document store\n",
      "2024-02-18 22:04:59.211 | INFO     | __main__:initialise_retriever:31 - Initialising retriever\n",
      "Batches: 100%|██████████| 24/24 [00:00<00:00, 31.38it/s]ocs/s]\n",
      "Documents Processed: 10000 docs [00:00, 12705.90 docs/s]       \n",
      "2024-02-18 22:05:02.079 | INFO     | __main__:initialise_generation_llm:40 - Initialising generation LLM\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 217.39it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 85.72it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 88.78it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 170.85it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 200.06it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 208.46it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.09it/s]\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 122.86it/s]\n"
     ]
    }
   ],
   "source": [
    "results = validate_rag(querying_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Year</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Source</th>\n",
       "      <th>Content Type</th>\n",
       "      <th>Page</th>\n",
       "      <th>Notes</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SASOL</td>\n",
       "      <td>2023</td>\n",
       "      <td>Number of permanent employees</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SASOL Sustainability Report 2023 20-09_0.pdf</td>\n",
       "      <td>Table</td>\n",
       "      <td>17</td>\n",
       "      <td>May get confuesed with employee numbers in tab...</td>\n",
       "      <td>28657</td>\n",
       "      <td>28657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SASOL</td>\n",
       "      <td>2023</td>\n",
       "      <td>Employee turnover</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SASOL Sustainability Report 2023 20-09_0.pdf</td>\n",
       "      <td>Text</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1725</td>\n",
       "      <td>1725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SASOL</td>\n",
       "      <td>2023</td>\n",
       "      <td>B-BBEE status</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SASOL Sustainability Report 2023 20-09_0.pdf</td>\n",
       "      <td>Table</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SASOL</td>\n",
       "      <td>2023</td>\n",
       "      <td>B-BBEE scorecard level</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SASOL Sustainability Report 2023 20-09_0.pdf</td>\n",
       "      <td>Table</td>\n",
       "      <td>57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SASOL</td>\n",
       "      <td>2023</td>\n",
       "      <td>Black women-owned spend</td>\n",
       "      <td>rand</td>\n",
       "      <td>SASOL Sustainability Report 2023 20-09_0.pdf</td>\n",
       "      <td>Text</td>\n",
       "      <td>11</td>\n",
       "      <td>May be retrieved from table. Requires conversi...</td>\n",
       "      <td>28500</td>\n",
       "      <td>28500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SASOL</td>\n",
       "      <td>2023</td>\n",
       "      <td>Black-owned spend</td>\n",
       "      <td>rand</td>\n",
       "      <td>SASOL Sustainability Report 2023 20-09_0.pdf</td>\n",
       "      <td>Text</td>\n",
       "      <td>11</td>\n",
       "      <td>Required conversion from million rand to rand</td>\n",
       "      <td>41700</td>\n",
       "      <td>41700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SASOL</td>\n",
       "      <td>2023</td>\n",
       "      <td>Number of fatalities</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SASOL Sustainability Report 2023 20-09_0.pdf</td>\n",
       "      <td>Text</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SASOL</td>\n",
       "      <td>2023</td>\n",
       "      <td>Number of undergraduate and postgraduate bursa...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SASOL Sustainability Report 2023 20-09_0.pdf</td>\n",
       "      <td>Text</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>544</td>\n",
       "      <td>544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company  Year                                             Metric  Unit  \\\n",
       "0   SASOL  2023                      Number of permanent employees   NaN   \n",
       "1   SASOL  2023                                  Employee turnover   NaN   \n",
       "2   SASOL  2023                                      B-BBEE status   NaN   \n",
       "3   SASOL  2023                             B-BBEE scorecard level   NaN   \n",
       "4   SASOL  2023                            Black women-owned spend  rand   \n",
       "5   SASOL  2023                                  Black-owned spend  rand   \n",
       "6   SASOL  2023                               Number of fatalities   NaN   \n",
       "7   SASOL  2023  Number of undergraduate and postgraduate bursa...   NaN   \n",
       "\n",
       "                                         Source Content Type  Page  \\\n",
       "0  SASOL Sustainability Report 2023 20-09_0.pdf        Table    17   \n",
       "1  SASOL Sustainability Report 2023 20-09_0.pdf         Text    18   \n",
       "2  SASOL Sustainability Report 2023 20-09_0.pdf        Table    57   \n",
       "3  SASOL Sustainability Report 2023 20-09_0.pdf        Table    57   \n",
       "4  SASOL Sustainability Report 2023 20-09_0.pdf         Text    11   \n",
       "5  SASOL Sustainability Report 2023 20-09_0.pdf         Text    11   \n",
       "6  SASOL Sustainability Report 2023 20-09_0.pdf         Text    11   \n",
       "7  SASOL Sustainability Report 2023 20-09_0.pdf         Text    18   \n",
       "\n",
       "                                               Notes  Answer Generated  \n",
       "0  May get confuesed with employee numbers in tab...   28657     28657  \n",
       "1                                                NaN    1725      1725  \n",
       "2                                                NaN       3         3  \n",
       "3                                                NaN       3         3  \n",
       "4  May be retrieved from table. Requires conversi...   28500     28500  \n",
       "5      Required conversion from million rand to rand   41700     41700  \n",
       "6                                                NaN       2         2  \n",
       "7                                                NaN     544       544  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryPipeline:\n",
    "    def __init__(\n",
    "            self,\n",
    "            docs: list[Document],\n",
    "            company: str,\n",
    "            amkey_to_metric_path: str,\n",
    "            amkey_to_synonym_path: str,\n",
    "            amkey_to_unit_path : str\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Initalise the components of the query pipeline.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        docs : list[Document]\n",
    "            The documents to provide context for the queries.\n",
    "\n",
    "        company : str\n",
    "            The company the documents are for.\n",
    "\n",
    "        amkey_to_metric_path : str\n",
    "            Path to a csv file mapping AMKEY to metric.\n",
    "\n",
    "        amkey_to_synonym_path : str\n",
    "            Path to a csv file mapping AMKEY and company to metric synonym.\n",
    "\n",
    "        amkey_to_unit_path : str\n",
    "            Path to a csv file mapping AMKEY to desired unit.\n",
    "        \"\"\"\n",
    "        self.docs = docs\n",
    "        self.company = company\n",
    "        self.amkey_to_metric_path = amkey_to_metric_path\n",
    "        self.amkey_to_synonym_path = amkey_to_synonym_path\n",
    "        self.amkey_to_unit_path = amkey_to_unit_path\n",
    "\n",
    "        self.document_store = None\n",
    "        self.retriever = None\n",
    "        self.generation_llm = None\n",
    "        self.unit_conversion_llm = None\n",
    "        self.amkey_to_metric = None\n",
    "        self.amkey_to_synonym = None\n",
    "        self.amkey_to_unit = None\n",
    "\n",
    "        self.initialise_document_store()\n",
    "        self.initialise_retriever()\n",
    "        self.initialise_generation_llm()\n",
    "        self.initialise_unit_conversion_llm()\n",
    "        self.initialise_mappings()\n",
    "\n",
    "    def initialise_document_store(self):\n",
    "        logger.info(\"Initialising document store\")\n",
    "        self.document_store = InMemoryDocumentStore(embedding_dim=384)\n",
    "        self.document_store.delete_documents()\n",
    "        self.document_store.write_documents(docs)\n",
    "\n",
    "    def initialise_retriever(self, top_k=3):\n",
    "        logger.info(\"Initialising retriever\")\n",
    "        self.retriever = EmbeddingRetriever(\n",
    "            embedding_model=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "            document_store=self.document_store,\n",
    "            top_k=top_k\n",
    "        )\n",
    "        self.document_store.update_embeddings(retriever=self.retriever)\n",
    "\n",
    "    def initialise_generation_llm(self):\n",
    "        logger.info(\"Initialising generation LLM\")\n",
    "        self.generation_llm = PromptNode(\n",
    "            model_name_or_path=\"gpt-3.5-turbo-1106\",\n",
    "            api_key=OPENAI_API_KEY,\n",
    "            model_kwargs={\"temperature\": 0}\n",
    "        )\n",
    "\n",
    "    def initialise_unit_conversion_llm(self):\n",
    "        logger.info(\"Initialising unit conversion LLM\")\n",
    "        self.unit_conversion_llm = PromptNode(\n",
    "            model_name_or_path=\"gpt-3.5-turbo\",\n",
    "            api_key=OPENAI_API_KEY,\n",
    "            model_kwargs={\"temperature\": 0}\n",
    "        )\n",
    "\n",
    "    def initialise_mappings(self):\n",
    "        logger.info(\"Initialising mappings\")\n",
    "        self.amkey_to_metric = pd.read_csv(self.amkey_to_metric_path)\n",
    "        self.amkey_to_synonym = pd.read_csv(self.amkey_to_synonym_path)\n",
    "        self.amkey_to_unit = pd.read_csv(self.amkey_to_unit_path)\n",
    "\n",
    "    def query(self, amkey: int, year: int):\n",
    "        \"\"\"\n",
    "        Return the value associated with an AMKEY for a given year.\n",
    "\n",
    "        Uses retrieval augmented generation to retrieve the value.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        amkey : int\n",
    "            The AMKEY of the metric to retrieve.\n",
    "\n",
    "        year : int\n",
    "            The year to retrieve the metric for.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        value : int\n",
    "            The value associated with the AMKEY for the given year.\n",
    "        \"\"\"\n",
    "        metric = self.retrieve_company_metric_description(amkey)\n",
    "        if metric is None:\n",
    "            metric = self.retrieve_metric_description(amkey)\n",
    "        logger.debug(f\"Retrieving metric: {metric}\")\n",
    "\n",
    "        context_documents = self.retriever.retrieve(metric)\n",
    "\n",
    "        append = self._retrieve_additional_appended_instructions(amkey)\n",
    "        logger.debug(f\"Retrieved append: {append}\")\n",
    "\n",
    "        prompt = self._create_generation_prompt(metric, year, context_documents, append)\n",
    "\n",
    "        answer = self.generation_llm(prompt)[0]\n",
    "        logger.debug(f\"Generated answer: {answer}\")\n",
    "\n",
    "        value, unit = self.parse_answer(answer)\n",
    "\n",
    "        required_unit = self.retrieve_unit(amkey)\n",
    "        logger.debug(f\"Required unit: {required_unit}\")\n",
    "\n",
    "        if required_unit is not None:\n",
    "            if unit != required_unit:\n",
    "                unit_conversion_prompt = self.create_unit_conversion_prompt(value, unit, required_unit)\n",
    "                value = self.unit_conversion_llm(unit_conversion_prompt)\n",
    "\n",
    "        return value\n",
    "\n",
    "    def _retrieve_additional_appended_instructions(self, amkey: int) -> str:\n",
    "        \"\"\"\n",
    "        Return additional instructions to append to the query.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        amkey : int\n",
    "            The AMKEY of the metric to retrieve.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        append : str\n",
    "            Additional instructions to append to the query.\n",
    "        \"\"\"\n",
    "        if amkey in [47, 48, 49]:\n",
    "            append = \"Do not include the word 'Level' in the answer.\"\n",
    "        else:\n",
    "            append = \"\"\n",
    "\n",
    "        return append\n",
    "\n",
    "    def _create_generation_prompt(\n",
    "            self,\n",
    "            metric: str,\n",
    "            year: int,\n",
    "            docs: list[Document],\n",
    "            append: str\n",
    "        )-> str:\n",
    "        \"\"\"\n",
    "        Create a prompt for the generation LLM.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        metric : str\n",
    "            The metric to retrieve.\n",
    "\n",
    "        year : int\n",
    "            The year to retrieve the metric for.\n",
    "\n",
    "        docs : list[Document]\n",
    "            The documents to provide context for the queries.\n",
    "\n",
    "        append : str\n",
    "            Additional instructions to append to the query.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        prompt : str\n",
    "            The prompt for the generation LLM.\n",
    "        \"\"\"\n",
    "        query = f\"What was the {metric} in the year {year}?\"\n",
    "\n",
    "        context = \"\\n\\n\".join([doc.content for doc in docs])\n",
    "\n",
    "        prompt = f\"\"\"Use the following pieces of context to answer the question at the end.\n",
    "                    The context may be text or a markdown table.\n",
    "                    Just retrieve the answer from the context. Please don't do any unit conversion.\n",
    "                    If you don't know the answer, please return 'None' for the answer and unit.\n",
    "                    Do not return any words other than 'Answer' and 'Unit' in the answer.\n",
    "                    Please return the answer in the format 'Answer: <number or None>, Unit: <unit or None>'.\n",
    "\n",
    "                    \\n\\n Context: {context} \\n\\n Question: {query} {append}\\n\\n Answer:\"\"\"\n",
    "\n",
    "        return prompt\n",
    "\n",
    "    def create_unit_conversion_prompt(self, value: int, unit: str, target_unit: str) -> str:\n",
    "        prompt=f\"\"\"You are an expert unit converter. You are aware of how to convert\n",
    "                    between different units within the same system of measurement.\n",
    "                    For example, 1236 million = 1236 * 1 million = 1236 * 1000000 = 1236000000.\n",
    "                    For example, to convert from Rm to R, you would multiply by 1000000. This is because\n",
    "                    1 Rm = 1000000 R.\n",
    "                    Please return a single number as your answer. Do not elaborate or give\n",
    "                    any context.\\n\\n\n",
    "\n",
    "                    What is {value} {unit} in {target_unit}? \\n\\n Answer:\"\"\"\n",
    "\n",
    "        return prompt\n",
    "\n",
    "    def parse_answer(self, answer: str) -> tuple[float | None, str | None]:\n",
    "        \"\"\"\n",
    "        Parse the answer returned by the generation LLM.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        answer : str\n",
    "            The answer returned by the generation LLM. This is expected to be in the\n",
    "            format \"Answer: <number or None>, Unit: <unit or None>\".\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        value : float | None\n",
    "            The value from the answer.\n",
    "\n",
    "        unit : str | None\n",
    "            The unit from the answer.\n",
    "        \"\"\"\n",
    "        value, unit = answer.split(\", \")\n",
    "        value = value.split(\": \")[1]\n",
    "        unit = unit.split(\": \")[1]\n",
    "\n",
    "        if value == \"None\":\n",
    "            value = None\n",
    "        else:\n",
    "            value = value.replace(\" \", \"\")\n",
    "            value = value.replace(\",\", \"\")\n",
    "            value = float(value)\n",
    "\n",
    "        return value, unit\n",
    "\n",
    "    def retrieve_company_metric_description(self, amkey: int) -> str | None:\n",
    "        \"\"\"\n",
    "        Return the company-specific description of a metric, if available.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        amkey : int\n",
    "            The AMKEY of the metric.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        metric : str | None\n",
    "            The company-specific description of the metric, if available.\n",
    "            Otherwise, None.\n",
    "        \"\"\"\n",
    "        metric = self.amkey_to_synonym[\n",
    "            (self.amkey_to_synonym[\"AMKEY\"] == amkey)\n",
    "            & (self.amkey_to_synonym[\"Group\"] == self.company)\n",
    "        ][\"ClientMetric\"]\n",
    "\n",
    "        if metric.empty:\n",
    "            metric = None\n",
    "        else:\n",
    "            metric = metric.item()\n",
    "\n",
    "        return metric\n",
    "\n",
    "    def retrieve_metric_description(self, amkey: int) -> str:\n",
    "        \"\"\"\n",
    "        Return the description of a metric.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        amkey : int\n",
    "            The AMKEY of the metric.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        metric : str\n",
    "            The description of the metric.\n",
    "        \"\"\"\n",
    "        metric = self.amkey_to_metric[\n",
    "            self.amkey_to_metric[\"AMKEY\"] == amkey\n",
    "        ][\"ActivityMetric\"].item()\n",
    "\n",
    "        return metric\n",
    "\n",
    "    def retrieve_unit(self, amkey: int) -> str | None:\n",
    "        \"\"\"\n",
    "        Return the required unit for a metric.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        amkey : int\n",
    "            The AMKEY of the metric.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        unit : str | None\n",
    "            The required unit for the metric, if specified. Otherwise, None.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            unit = self.amkey_to_unit[self.amkey_to_unit[\"AMKEY\"] == amkey][\"Unit\"][0]\n",
    "        except KeyError:\n",
    "            unit = None\n",
    "\n",
    "        return unit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 19:21:48.489 | INFO     | __main__:initialise_document_store:51 - Initialising document store\n",
      "2024-02-19 19:21:48.496 | INFO     | __main__:initialise_retriever:57 - Initialising retriever\n",
      "Batches: 100%|██████████| 24/24 [00:00<00:00, 32.92it/s]ocs/s]\n",
      "Documents Processed: 10000 docs [00:00, 13329.84 docs/s]       \n",
      "2024-02-19 19:21:51.412 | INFO     | __main__:initialise_generation_llm:66 - Initialising generation LLM\n",
      "2024-02-19 19:21:51.413 | INFO     | __main__:initialise_unit_conversion_llm:74 - Initialising unit conversion LLM\n",
      "2024-02-19 19:21:51.414 | INFO     | __main__:initialise_mappings:82 - Initialising mappings\n"
     ]
    }
   ],
   "source": [
    "# TODO: Test the QueryPipeline class.\n",
    "query_pipeline = QueryPipeline(\n",
    "    docs=docs,\n",
    "    company=\"Sasol\",\n",
    "    amkey_to_metric_path=AMKEY_TO_METRIC_PATH,\n",
    "    amkey_to_synonym_path=AMKEY_TO_SYNONYM_PATH,\n",
    "    amkey_to_unit_path=AMKEY_TO_UNIT_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 19:21:53.054 | DEBUG    | __main__:retrieve_company_metric_description:262 - Retrieved client metric: 17    B-BBEE verification certificate\n",
      "Name: ClientMetric, dtype: object\n",
      "2024-02-19 19:21:53.055 | DEBUG    | __main__:query:109 - Retrieving metric: B-BBEE verification certificate\n",
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 199.31it/s]\n",
      "2024-02-19 19:21:53.091 | DEBUG    | __main__:query:114 - Retrieved append: Do not include the word 'Level' in the answer.\n",
      "2024-02-19 19:21:53.891 | DEBUG    | __main__:query:119 - Generated answer: Answer: 3, Unit: None\n",
      "2024-02-19 19:21:53.892 | DEBUG    | __main__:query:124 - Required unit: None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_pipeline.query(\n",
    "    amkey=49,\n",
    "    year=2023\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B-BBEE Scorecard Level'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_pipeline.retrieve_metric_description(49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-19 19:22:14.787 | DEBUG    | __main__:retrieve_company_metric_description:262 - Retrieved client metric: 17    B-BBEE verification certificate\n",
      "Name: ClientMetric, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'B-BBEE verification certificate'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_pipeline.retrieve_company_metric_description(49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haystack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
