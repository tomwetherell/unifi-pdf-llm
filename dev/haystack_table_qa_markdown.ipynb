{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tomw/miniconda3/envs/haystack/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/tomw/miniconda3/envs/haystack/lib/python3.10/site-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/tomw/miniconda3/envs/haystack/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/tomw/miniconda3/envs/haystack/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/home/tomw/miniconda3/envs/haystack/lib/python3.10/site-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Table QA - RAG approach with tables converted to markdown format.\n",
    "\n",
    "See https://haystack.deepset.ai/tutorials/22_pipeline_with_promptnode\n",
    "\"\"\"\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from haystack import Document\n",
    "from haystack.nodes import AzureConverter, EmbeddingRetriever, TableReader\n",
    "from haystack.document_stores import InMemoryDocumentStore\n",
    "from haystack.pipelines import Pipeline\n",
    "from haystack.utils import print_answers\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "AZURE_CONVERTER_KEY = os.environ.get(\"AZURE_CONVERTER_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = AzureConverter(\n",
    "    endpoint=\"https://azureconverter.cognitiveservices.azure.com/\",\n",
    "    credential_key=AZURE_CONVERTER_KEY,\n",
    "    save_json=True\n",
    ")\n",
    "\n",
    "PDF_PATH = Path(\"/home/tomw/unifi-pdf-llm/data/test/Sasol Sustainability Report_2021_22Sep21_10h30_0_0 - short.pdf\")\n",
    "\n",
    "docs = converter.convert(file_path=PDF_PATH, meta=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(df, window_size):\n",
    "    \"\"\"\n",
    "    Split a DataFrame into smaller DataFrames using a sliding window approach.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame to split.\n",
    "\n",
    "    window_size : int\n",
    "        The size of the sliding window.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of pandas.DataFrame\n",
    "        A list of DataFrames, each one representing a window of the original DataFrame.\n",
    "    \"\"\"\n",
    "    tables = [df.iloc[i:i+window_size] for i in range(len(df) - window_size + 1)]\n",
    "    tables = [table.reset_index(drop=True) for table in tables]\n",
    "\n",
    "    return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_table(doc, window_size=5):\n",
    "    \"\"\"\n",
    "    Split a table into smaller tables using a sliding window approach.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc : Document\n",
    "        The document containing the table to split.\n",
    "\n",
    "    window_size : int\n",
    "        The size of the sliding window.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    docs : list[Document]\n",
    "        A list of documents, each one containing a smaller table.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If the document does not contain a table.\n",
    "    \"\"\"\n",
    "    if doc.content_type != \"table\":\n",
    "        raise ValueError(\"The document does not contain a table.\")\n",
    "\n",
    "    tables = sliding_window(doc.content, window_size)\n",
    "    docs = []\n",
    "    for table in tables:\n",
    "        new_doc = Document(content=table)\n",
    "        for attr, value in doc.__dict__.items():\n",
    "            if attr != 'content':\n",
    "                setattr(new_doc, attr, value)\n",
    "        docs.append(new_doc)\n",
    "\n",
    "    return docs\n",
    "\n",
    "\n",
    "def split_tables(docs: list[Document], window_size: int=5):\n",
    "    \"\"\"\n",
    "    Return a list of documents, each containing text or a smaller table.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    docs : list[Document]\n",
    "        List of documents.\n",
    "\n",
    "    window_size : int\n",
    "        The size of the sliding window to use when splitting tables.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    new_docs : list[Document]\n",
    "        List of documents, each containing text or a smaller table.\n",
    "    \"\"\"\n",
    "    new_docs = []\n",
    "\n",
    "    for doc in docs:\n",
    "        if doc.content_type == \"table\":\n",
    "            new_docs.extend(split_table(doc, window_size))\n",
    "        else:\n",
    "            new_docs.append(doc)\n",
    "\n",
    "    return new_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_split = split_tables(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_table_to_markdown(doc: Document) -> None:\n",
    "    \"\"\"\n",
    "    Convert table to markdown format in place.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc : Document\n",
    "        Document with `content_type` table.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If `doc.content_type` is not \"table\".\n",
    "    \"\"\"\n",
    "    if doc.content_type != \"table\":\n",
    "        raise ValueError(f\"Document content_type must be 'table', not '{doc.content_type}'\")\n",
    "\n",
    "    table = doc.content\n",
    "    markdown_table = table.to_markdown(tablefmt=\"github\")\n",
    "\n",
    "    doc.content = markdown_table\n",
    "    doc.content_type = \"text\"\n",
    "\n",
    "\n",
    "def convert_tables_to_markdown(docs: list[Document]) -> None:\n",
    "    \"\"\"\n",
    "    Convert tables to markdown format in place.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    docs : List[Document]\n",
    "        List of Documents with `content_type` table.\n",
    "    \"\"\"\n",
    "    for doc in docs:\n",
    "        if doc.content_type == \"table\":\n",
    "            convert_table_to_markdown(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_tables_to_markdown(docs_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "379"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Move to utils.py module\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str=\"cl100k_base\") -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "num_tokens_from_string(docs_split[1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store = InMemoryDocumentStore(embedding_dim=384)\n",
    "\n",
    "document_store.delete_documents()\n",
    "document_store.write_documents(docs_split, duplicate_documents='fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_store.get_document_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: I'm not sure what OpenAI embedding models are available. Is it possible to use\n",
    "# their newest embedding models in Haystack v1?\n",
    "\n",
    "retriever = EmbeddingRetriever(\n",
    "    embedding_model=\"sentence-transformers/all-MiniLM-L6-v2\", document_store=document_store\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  3.39it/s]ocs/s]\n",
      "Documents Processed: 10000 docs [00:00, 33328.81 docs/s]     \n"
     ]
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_store.get_document_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems not all the documents are getting written to the document store..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haystack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
