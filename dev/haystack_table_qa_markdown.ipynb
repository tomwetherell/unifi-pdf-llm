{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Table QA - RAG approach with tables converted to markdown format.\n",
    "\n",
    "See https://haystack.deepset.ai/tutorials/22_pipeline_with_promptnode\n",
    "\"\"\"\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from haystack import Document\n",
    "from haystack.nodes import AzureConverter, EmbeddingRetriever, TableReader\n",
    "from haystack.document_stores import InMemoryDocumentStore\n",
    "from haystack.pipelines import Pipeline\n",
    "from haystack.utils import print_answers\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "AZURE_CONVERTER_KEY = os.environ.get(\"AZURE_CONVERTER_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = AzureConverter(\n",
    "    endpoint=\"https://azureconverter.cognitiveservices.azure.com/\",\n",
    "    credential_key=AZURE_CONVERTER_KEY,\n",
    "    save_json=True\n",
    ")\n",
    "\n",
    "PDF_PATH = Path(\"/home/tomw/unifi-pdf-llm/data/test/Sasol Sustainability Report_2021_22Sep21_10h30_0_0 - short.pdf\")\n",
    "\n",
    "docs = converter.convert(file_path=PDF_PATH, meta=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_table_to_markdown(doc: Document) -> None:\n",
    "    \"\"\"\n",
    "    Convert table to markdown format in place.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc : Document\n",
    "        Document with `content_type` table.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If `doc.content_type` is not \"table\".\n",
    "    \"\"\"\n",
    "    if doc.content_type != \"table\":\n",
    "        raise ValueError(f\"Document content_type must be 'table', not '{doc.content_type}'\")\n",
    "\n",
    "    table = doc.content\n",
    "    markdown_table = table.to_markdown(tablefmt=\"github\")\n",
    "\n",
    "    doc.content = markdown_table\n",
    "    doc.content_type = \"text\"\n",
    "\n",
    "\n",
    "def convert_tables_to_markdown(docs: list[Document]) -> None:\n",
    "    \"\"\"\n",
    "    Convert tables to markdown format in place.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    docs : List[Document]\n",
    "        List of Documents with `content_type` table.\n",
    "    \"\"\"\n",
    "    for doc in docs:\n",
    "        if doc.content_type == \"table\":\n",
    "            convert_table_to_markdown(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_tables_to_markdown(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "document_store = InMemoryDocumentStore()\n",
    "\n",
    "document_store.write_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config_sentence_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 702kB/s]\n",
      "modules.json: 100%|██████████| 349/349 [00:00<00:00, 2.55MB/s]\n",
      "README.md: 100%|██████████| 10.6k/10.6k [00:00<00:00, 52.4MB/s]\n",
      "sentence_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 338kB/s]\n",
      "config.json: 100%|██████████| 612/612 [00:00<00:00, 4.56MB/s]\n",
      "pytorch_model.bin: 100%|██████████| 90.9M/90.9M [00:18<00:00, 4.95MB/s]\n",
      "tokenizer_config.json: 100%|██████████| 350/350 [00:00<00:00, 2.43MB/s]\n",
      "vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 2.69MB/s]\n",
      "tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 1.75MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 112/112 [00:00<00:00, 823kB/s]\n",
      "1_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 1.37MB/s]\n",
      "Batches: 100%|██████████| 1/1 [00:01<00:00,  1.51s/it]ocs/s]\n",
      "Updating Embedding:   0%|          | 0/4 [00:01<?, ? docs/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Embedding dimensions of the model (384) don't match the embedding dimensions of the document store (768). Initiate InMemoryDocumentStore again with arg embedding_dim=384.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# TODO: I'm not sure what OpenAI embedding models are available. Is it possible to use\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# their newest embeedding models?\u001b[39;00m\n\u001b[1;32m      4\u001b[0m retriever \u001b[38;5;241m=\u001b[39m EmbeddingRetriever(\n\u001b[1;32m      5\u001b[0m     embedding_model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentence-transformers/all-MiniLM-L6-v2\u001b[39m\u001b[38;5;124m\"\u001b[39m, document_store\u001b[38;5;241m=\u001b[39mdocument_store\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 8\u001b[0m \u001b[43mdocument_store\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretriever\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretriever\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/haystack/lib/python3.10/site-packages/haystack/document_stores/memory.py:569\u001b[0m, in \u001b[0;36mInMemoryDocumentStore.update_embeddings\u001b[0;34m(self, retriever, index, filters, update_existing_embeddings, batch_size)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m document_batch \u001b[38;5;129;01min\u001b[39;00m batched_documents:\n\u001b[1;32m    568\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m retriever\u001b[38;5;241m.\u001b[39membed_documents(document_batch)\n\u001b[0;32m--> 569\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_embeddings_shape\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m        \u001b[49m\u001b[43membeddings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_documents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdocument_batch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_dim\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    573\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m doc, emb \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(document_batch, embeddings):\n\u001b[1;32m    574\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindexes[index][doc\u001b[38;5;241m.\u001b[39mid]\u001b[38;5;241m.\u001b[39membedding \u001b[38;5;241m=\u001b[39m emb\n",
      "File \u001b[0;32m~/miniconda3/envs/haystack/lib/python3.10/site-packages/haystack/document_stores/base.py:692\u001b[0m, in \u001b[0;36mBaseDocumentStore._validate_embeddings_shape\u001b[0;34m(cls, embeddings, num_documents, embedding_dim)\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m DocumentStoreError(\n\u001b[1;32m    688\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe number of embeddings does not match the number of documents: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    689\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_embeddings\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m != \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_documents\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    690\u001b[0m     )\n\u001b[1;32m    691\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m embedding_size \u001b[38;5;241m!=\u001b[39m embedding_dim:\n\u001b[0;32m--> 692\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    693\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbedding dimensions of the model (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00membedding_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt match the embedding dimensions of the document store (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00membedding_dim\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m). \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    694\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInitiate \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m again with arg embedding_dim=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00membedding_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    695\u001b[0m     )\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Embedding dimensions of the model (384) don't match the embedding dimensions of the document store (768). Initiate InMemoryDocumentStore again with arg embedding_dim=384."
     ]
    }
   ],
   "source": [
    "# TODO: I'm not sure what OpenAI embedding models are available. Is it possible to use\n",
    "# their newest embedding models in Haystack v1?\n",
    "\n",
    "retriever = EmbeddingRetriever(\n",
    "    embedding_model=\"sentence-transformers/all-MiniLM-L6-v2\", document_store=document_store\n",
    ")\n",
    "\n",
    "document_store.update_embeddings(retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haystack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
