{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Table QA - RAG approach with tables converted to markdown format.\n",
    "\n",
    "See https://haystack.deepset.ai/tutorials/22_pipeline_with_promptnode\n",
    "\"\"\"\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from haystack import Document\n",
    "from haystack.nodes import AzureConverter, EmbeddingRetriever, PromptNode, PromptTemplate, AnswerParser\n",
    "from haystack.document_stores import InMemoryDocumentStore\n",
    "from haystack.pipelines import Pipeline\n",
    "from haystack.utils import print_answers\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "AZURE_CONVERTER_KEY = os.environ.get(\"AZURE_CONVERTER_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = AzureConverter(\n",
    "    endpoint=\"https://azureconverter.cognitiveservices.azure.com/\",\n",
    "    credential_key=AZURE_CONVERTER_KEY,\n",
    "    save_json=True\n",
    ")\n",
    "\n",
    "PDF_PATH = Path(\"/home/tomw/unifi-pdf-llm/data/test/Sasol Sustainability Report_2021_22Sep21_10h30_0_0 - short.pdf\")\n",
    "\n",
    "docs = converter.convert(file_path=PDF_PATH, meta=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(df, window_size):\n",
    "    \"\"\"\n",
    "    Split a DataFrame into smaller DataFrames using a sliding window approach.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame to split.\n",
    "\n",
    "    window_size : int\n",
    "        The size of the sliding window.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of pandas.DataFrame\n",
    "        A list of DataFrames, each one representing a window of the original DataFrame.\n",
    "    \"\"\"\n",
    "    tables = [df.iloc[i:i+window_size] for i in range(len(df) - window_size + 1)]\n",
    "\n",
    "    return tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_table(doc, window_size=5):\n",
    "    \"\"\"\n",
    "    Split a table into smaller tables using a sliding window approach.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc : Document\n",
    "        The document containing the table to split.\n",
    "\n",
    "    window_size : int\n",
    "        The size of the sliding window.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    docs : list[Document]\n",
    "        A list of documents, each one containing a smaller table.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If the document does not contain a table.\n",
    "    \"\"\"\n",
    "    if doc.content_type != \"table\":\n",
    "        raise ValueError(\"The document does not contain a table.\")\n",
    "\n",
    "    tables = sliding_window(doc.content, window_size)\n",
    "    docs = []\n",
    "    for table in tables:\n",
    "        new_doc = Document(content=table)\n",
    "        for attr, value in doc.__dict__.items():\n",
    "            if attr not in [\"content\", \"id\"]:\n",
    "                setattr(new_doc, attr, value)\n",
    "        docs.append(new_doc)\n",
    "\n",
    "    return docs\n",
    "\n",
    "\n",
    "def split_tables(docs: list[Document], window_size: int=5):\n",
    "    \"\"\"\n",
    "    Return a list of documents, each containing text or a smaller table.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    docs : list[Document]\n",
    "        List of documents.\n",
    "\n",
    "    window_size : int\n",
    "        The size of the sliding window to use when splitting tables.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    new_docs : list[Document]\n",
    "        List of documents, each containing text or a smaller table.\n",
    "    \"\"\"\n",
    "    new_docs = []\n",
    "\n",
    "    for doc in docs:\n",
    "        if doc.content_type == \"table\":\n",
    "            new_docs.extend(split_table(doc, window_size))\n",
    "        else:\n",
    "            new_docs.append(doc)\n",
    "\n",
    "    return new_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_split = split_tables(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_table_to_markdown(doc: Document) -> None:\n",
    "    \"\"\"\n",
    "    Convert table to markdown format in place.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc : Document\n",
    "        Document with `content_type` table.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If `doc.content_type` is not \"table\".\n",
    "    \"\"\"\n",
    "    if doc.content_type != \"table\":\n",
    "        raise ValueError(f\"Document content_type must be 'table', not '{doc.content_type}'\")\n",
    "\n",
    "    table = doc.content\n",
    "    markdown_table = table.to_markdown(tablefmt=\"github\")\n",
    "\n",
    "    doc.content = markdown_table\n",
    "    doc.content_type = \"text\"\n",
    "\n",
    "\n",
    "def convert_tables_to_markdown(docs: list[Document]) -> None:\n",
    "    \"\"\"\n",
    "    Convert tables to markdown format in place.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    docs : List[Document]\n",
    "        List of Documents with `content_type` table.\n",
    "    \"\"\"\n",
    "    for doc in docs:\n",
    "        if doc.content_type == \"table\":\n",
    "            convert_table_to_markdown(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_tables_to_markdown(docs_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "379"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Move to utils.py module\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str=\"cl100k_base\") -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "num_tokens_from_string(docs_split[1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try to use other document stores (e.g. FAISS).\n",
    "\n",
    "document_store = InMemoryDocumentStore(embedding_dim=384)\n",
    "\n",
    "document_store.delete_documents()\n",
    "document_store.write_documents(docs_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: I'm not sure what OpenAI embedding models are available. Is it possible to use\n",
    "# their newest embedding models in Haystack v1?\n",
    "\n",
    "# TODO: Look into other (non-OpenAI) embedding models that can be used with Haystack v1.\n",
    "\n",
    "retriever = EmbeddingRetriever(\n",
    "    embedding_model=\"sentence-transformers/all-MiniLM-L6-v2\", document_store=document_store\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 5/5 [00:00<00:00, 10.28it/s] docs/s]\n",
      "Documents Processed: 10000 docs [00:00, 19648.59 docs/s]       \n"
     ]
    }
   ],
   "source": [
    "document_store.update_embeddings(retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 59.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | Natural Capital - Our environment            | Footnote   | 2021   | 2020   | 2019   | 2018   | Level of assurance 2021   |\n",
      "|----|----------------------------------------------|------------|--------|--------|--------|--------|---------------------------|\n",
      "|  7 | Americas                                     |            | 1 225  | 1 695  | 688    | 707    |                           |\n",
      "|  8 | Mozambique                                   |            | 42     | 46     | 53     | 54     |                           |\n",
      "|  9 | Other strategic business units and Functions |            | 782    | 679    | 745    | 659    |                           |\n",
      "| 10 | Greenhouse gases (GHG) (kilotons)            | 12         |        |        |        |        |                           |\n",
      "| 11 | Direct methane (CH2)                         |            | 116,14 | 106,00 | 105,04 | 109,18 | Reasonable                |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test the retriever\n",
    "\n",
    "# Try the Retriever\n",
    "retrieved_tables = retriever.retrieve(\"What was the GHG Scope 2 emissions in the year 2021?\", top_k=3)\n",
    "\n",
    "# Get highest scored table\n",
    "print(retrieved_tables[2].content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_prompt = PromptTemplate(\n",
    "    prompt=\"\"\"Use the following pieces of context to answer the question at the end.\n",
    "              The context may be text or a markdown table.\n",
    "              If you don't know the answer, just say 'None', don't try to make up an answer.\n",
    "\n",
    "              \\n\\n Context: {join(documents)} \\n\\n Question: {query} \\n\\n Answer:\"\"\",\n",
    "    output_parser=AnswerParser(),\n",
    ")\n",
    "\n",
    "\n",
    "prompt_node = PromptNode(model_name_or_path=\"gpt-3.5-turbo\", api_key=OPENAI_API_KEY, default_prompt_template=rag_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: How to specify the number of documents retrieved by the retriever to use in the prompt?\n",
    "\n",
    "pipe = Pipeline()\n",
    "pipe.add_node(component=retriever, name=\"retriever\", inputs=[\"Query\"])\n",
    "pipe.add_node(component=prompt_node, name=\"prompt_node\", inputs=[\"retriever\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 29.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56,972 kilotons\n"
     ]
    }
   ],
   "source": [
    "output = pipe.run(query=\"What was the GHG Scope 1 emissions in the year 2021?\")\n",
    "\n",
    "print(output[\"answers\"][0].answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 82.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "output = pipe.run(query=\"What was the GHG Scope 2 emissions in the year 2021?\")\n",
    "\n",
    "print(output[\"answers\"][0].answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working very well. Only issue I have seen so far is not being able to answer \"What was the \n",
    "GHG Scope 2 emissions in the year 2021?\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haystack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
