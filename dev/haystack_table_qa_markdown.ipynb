{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Table QA - RAG approach with tables converted to markdown format.\n",
    "\n",
    "See https://haystack.deepset.ai/tutorials/22_pipeline_with_promptnode\n",
    "\"\"\"\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from haystack import Document\n",
    "from haystack.nodes import AzureConverter, EmbeddingRetriever, PromptNode, PromptTemplate, AnswerParser\n",
    "from haystack.document_stores import InMemoryDocumentStore\n",
    "from haystack.pipelines import Pipeline\n",
    "from haystack.utils import print_answers\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "AZURE_CONVERTER_KEY = os.environ.get(\"AZURE_CONVERTER_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = AzureConverter(\n",
    "    endpoint=\"https://azureconverter.cognitiveservices.azure.com/\",\n",
    "    credential_key=AZURE_CONVERTER_KEY,\n",
    "    model_id=\"prebuilt-layout\",  # Was \"prebuilt-document\"\n",
    "    save_json=False\n",
    ")\n",
    "\n",
    "PDF_PATH = Path(\"/home/tomw/unifi-pdf-llm/data/validate/SASOL Sustainability Report 2023 20-09_0_minimal.pdf\")\n",
    "\n",
    "docs = converter.convert(file_path=PDF_PATH, meta=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement way to save docs to disk and load them back in. Would be good to do at this\n",
    "# stage (before loaded into a document store), so it's possible to experiment with the\n",
    "# indexing pipeline without having to re-convert the PDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 3\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of documents: {len(docs)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tables(docs: list[Document], window_size: int=5):\n",
    "    \"\"\"\n",
    "    Return a list of documents, each containing text or a smaller table.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    docs : list[Document]\n",
    "        List of documents.\n",
    "\n",
    "    window_size : int\n",
    "        The size of the sliding window to use when splitting tables.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    new_docs : list[Document]\n",
    "        List of documents, each containing text or a smaller table.\n",
    "    \"\"\"\n",
    "    new_docs = []\n",
    "\n",
    "    for doc in docs:\n",
    "        if doc.content_type == \"table\":\n",
    "            new_docs.extend(_split_table(doc, window_size))\n",
    "        else:\n",
    "            new_docs.append(doc)\n",
    "\n",
    "    return new_docs\n",
    "\n",
    "\n",
    "def _split_table(doc, window_size=5):\n",
    "    \"\"\"\n",
    "    Split a table into smaller tables using a sliding window approach.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc : Document\n",
    "        The document containing the table to split.\n",
    "\n",
    "    window_size : int\n",
    "        The size of the sliding window.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    docs : list[Document]\n",
    "        A list of documents, each one containing a smaller table.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If the document does not contain a table.\n",
    "    \"\"\"\n",
    "    if doc.content_type != \"table\":\n",
    "        raise ValueError(\"The document does not contain a table.\")\n",
    "\n",
    "    tables = _sliding_window(doc.content, window_size)\n",
    "    docs = []\n",
    "    for table in tables:\n",
    "        new_doc = Document(content=table)\n",
    "        for attr, value in doc.__dict__.items():\n",
    "            if attr not in [\"content\", \"id\"]:\n",
    "                setattr(new_doc, attr, value)\n",
    "        docs.append(new_doc)\n",
    "\n",
    "    return docs\n",
    "\n",
    "\n",
    "def _sliding_window(df, window_size):\n",
    "    \"\"\"\n",
    "    Split a DataFrame into smaller DataFrames using a sliding window approach.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The DataFrame to split.\n",
    "\n",
    "    window_size : int\n",
    "        The size of the sliding window.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of pandas.DataFrame\n",
    "        A list of DataFrames, each one representing a window of the original DataFrame.\n",
    "    \"\"\"\n",
    "    tables = [df.iloc[i:i+window_size] for i in range(len(df) - window_size + 1)]\n",
    "\n",
    "    return tables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 140\n"
     ]
    }
   ],
   "source": [
    "docs = split_tables(docs)\n",
    "\n",
    "print(f\"Number of documents: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_tables_to_markdown(docs: list[Document]) -> None:\n",
    "    \"\"\"\n",
    "    Convert tables to markdown format in place.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    docs : List[Document]\n",
    "        List of Documents with `content_type` table.\n",
    "    \"\"\"\n",
    "    for doc in docs:\n",
    "        if doc.content_type == \"table\":\n",
    "            _convert_table_to_markdown(doc)\n",
    "\n",
    "\n",
    "def _convert_table_to_markdown(doc: Document) -> None:\n",
    "    \"\"\"\n",
    "    Convert table to markdown format in place.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    doc : Document\n",
    "        Document with `content_type` table.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        If `doc.content_type` is not \"table\".\n",
    "    \"\"\"\n",
    "    if doc.content_type != \"table\":\n",
    "        raise ValueError(f\"Document content_type must be 'table', not '{doc.content_type}'\")\n",
    "\n",
    "    table = doc.content\n",
    "    markdown_table = table.to_markdown(tablefmt=\"github\")\n",
    "\n",
    "    doc.content = markdown_table\n",
    "    doc.content_type = \"text\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert_tables_to_markdown(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Try to use other document stores (e.g. FAISS).\n",
    "\n",
    "document_store = InMemoryDocumentStore(embedding_dim=384)\n",
    "\n",
    "document_store.delete_documents()\n",
    "document_store.write_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 5/5 [00:00<00:00, 12.47it/s] docs/s]\n",
      "Documents Processed: 10000 docs [00:00, 24072.74 docs/s]       \n"
     ]
    }
   ],
   "source": [
    "# TODO: I'm not sure what OpenAI embedding models are available. Is it possible to use\n",
    "# their newest embedding models in Haystack v1?\n",
    "\n",
    "# TODO: Look into other (non-OpenAI) embedding models that can be used with Haystack v1.\n",
    "\n",
    "retriever = EmbeddingRetriever(\n",
    "    embedding_model=\"sentence-transformers/all-MiniLM-L6-v2\", document_store=document_store\n",
    ")\n",
    "\n",
    "document_store.update_embeddings(retriever=retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 140.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | Natural Capital - Our environment            | Footnote   | 2021   | 2020          | 2019         | 2018   | Level of assurance 2021   |\n",
      "|----|----------------------------------------------|------------|--------|---------------|--------------|--------|---------------------------|\n",
      "| 46 |                                              |            |        | 313           | 223          | 162    | Restated                  |\n",
      "| 47 | Americas                                     |            | 264    | 313           | 223          | 162    | 2018-2020                 |\n",
      "| 48 | Mozambique                                   |            | -      |               |              | -      |                           |\n",
      "| 49 | Other strategic business units and Functions |            | 25     | 28            | 36           | 37     |                           |\n",
      "| 50 | Indirect carbon dioxide (CO2) Scope 3        |            | Refer  | to page 4, 30 | to 32 of the | CCR    | Limited                   |\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing the retriever\n",
    "\n",
    "# Try the Retriever\n",
    "retrieved_tables = retriever.retrieve(\"What was the GHG Scope 2 emissions in the year 2021?\", top_k=3)\n",
    "\n",
    "# Get highest scored table\n",
    "print(retrieved_tables[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_prompt = PromptTemplate(\n",
    "    prompt=\"\"\"Use the following pieces of context to answer the question at the end.\n",
    "              The context may be text or a markdown table.\n",
    "              If you don't know the answer, just say 'None', don't try to make up an answer.\n",
    "\n",
    "              \\n\\n Context: {join(documents)} \\n\\n Question: {query} \\n\\n Answer:\"\"\",\n",
    "    output_parser=AnswerParser(),\n",
    ")\n",
    "\n",
    "prompt_node = PromptNode(\n",
    "    model_name_or_path=\"gpt-3.5-turbo\",\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    default_prompt_template=rag_prompt,\n",
    "    model_kwargs={\"temperature\": 0.0}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: How to specify the number of documents retrieved by the retriever to use in the prompt?\n",
    "\n",
    "querying_pipeline = Pipeline()\n",
    "querying_pipeline.add_node(component=retriever, name=\"retriever\", inputs=[\"Query\"])\n",
    "querying_pipeline.add_node(component=prompt_node, name=\"prompt_node\", inputs=[\"retriever\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 98.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56,972\n"
     ]
    }
   ],
   "source": [
    "output = querying_pipeline.run(query=\"What was the GHG Scope 1 emissions in the year 2021?\")\n",
    "\n",
    "print(output[\"answers\"][0].answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 34.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "output = querying_pipeline.run(query=\"What was the GHG Scope 2 emissions in the year 2021?\")\n",
    "\n",
    "print(output[\"answers\"][0].answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working very well. Only issue I have seen so far is not being able to answer \"What was the \n",
    "GHG Scope 2 emissions in the year 2021?\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "VALIDATION_FILE = Path(\"/home/tomw/unifi-pdf-llm/data/validate/rag_esg_metric_validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_FILE = Path(\"/home/tomw/unifi-pdf-llm/data/validate/rag_esg_metric_validation.csv\")\n",
    "VALIDATION_PDF = Path(\"\")\n",
    "\n",
    "def validate_rag(querying_pipeline: Pipeline):\n",
    "    validation_df = pd.read_csv(VALIDATION_FILE)\n",
    "    results_df = validation_df.copy(deep=True)\n",
    "\n",
    "    # Add row to results_df for the generated answer\n",
    "    results_df[\"Generated\"] = None\n",
    "\n",
    "    for idx, row in validation_df.iterrows():\n",
    "        year = row[\"Year\"]\n",
    "        metric = row[\"Metric\"]\n",
    "        unit = row[\"Unit\"]\n",
    "\n",
    "        if unit is not None:\n",
    "            query = f\"What was the {metric} in the year {year}?\"\n",
    "        else:\n",
    "            query = f\"What was the {metric} in the year {year}? Please give your answer in the unit {unit}.\"\n",
    "\n",
    "        output = querying_pipeline.run(query=query)\n",
    "        answer = output[\"answers\"][0].answer\n",
    "\n",
    "        results_df.at[idx, \"Generated\"] = answer\n",
    "\n",
    "    return results_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = pd.read_csv(VALIDATION_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Year</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Source</th>\n",
       "      <th>Content Type</th>\n",
       "      <th>Page</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SASOL</td>\n",
       "      <td>2023</td>\n",
       "      <td>Number of permanent employees</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26294</td>\n",
       "      <td>SASOL Sustainability Report 2023 20-09_0.pdf</td>\n",
       "      <td>Table</td>\n",
       "      <td>17</td>\n",
       "      <td>May get confuesed with employee numbers in tab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SASOL</td>\n",
       "      <td>2023</td>\n",
       "      <td>Employee turnover</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1725</td>\n",
       "      <td>SASOL Sustainability Report 2023 20-09_0.pdf</td>\n",
       "      <td>Text</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SASOL</td>\n",
       "      <td>2023</td>\n",
       "      <td>GHG Scope 1 emissions</td>\n",
       "      <td>kilotons</td>\n",
       "      <td>58644</td>\n",
       "      <td>SASOL Sustainability Report 2023 20-09_0.pdf</td>\n",
       "      <td>Table</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SASOL</td>\n",
       "      <td>2023</td>\n",
       "      <td>GHG Scope 2 emissions</td>\n",
       "      <td>kilotons</td>\n",
       "      <td>5748</td>\n",
       "      <td>SASOL Sustainability Report 2023 20-09_0.pdf</td>\n",
       "      <td>Table</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SASOL</td>\n",
       "      <td>2023</td>\n",
       "      <td>GHG Scope 3 emissions</td>\n",
       "      <td>kilotons</td>\n",
       "      <td>36664</td>\n",
       "      <td>SASOL Sustainability Report 2023 20-09_0.pdf</td>\n",
       "      <td>Table</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Company  Year                          Metric      Unit  Answer  \\\n",
       "0   SASOL   2023  Number of permanent employees       NaN   26294   \n",
       "1   SASOL   2023              Employee turnover       NaN    1725   \n",
       "2   SASOL   2023          GHG Scope 1 emissions  kilotons   58644   \n",
       "3   SASOL   2023         GHG Scope 2 emissions   kilotons    5748   \n",
       "4   SASOL   2023         GHG Scope 3 emissions   kilotons   36664   \n",
       "\n",
       "                                         Source Content Type  Page  \\\n",
       "0  SASOL Sustainability Report 2023 20-09_0.pdf        Table    17   \n",
       "1  SASOL Sustainability Report 2023 20-09_0.pdf         Text    18   \n",
       "2  SASOL Sustainability Report 2023 20-09_0.pdf        Table    40   \n",
       "3  SASOL Sustainability Report 2023 20-09_0.pdf        Table    40   \n",
       "4  SASOL Sustainability Report 2023 20-09_0.pdf        Table    40   \n",
       "\n",
       "                                               Notes  \n",
       "0  May get confuesed with employee numbers in tab...  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haystack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
